{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Homework 2\n",
    "#### Student: Liyan Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bias-Variance Trade-off of LASSO\n",
    "#### While it is hard to write the explicit formula for the bias and variance of using LASSO, we can quantify the expected general trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) What is the general trend of the bias as λ increases?\n",
    "\n",
    "The bias will increase as $\\lambda$ increases, because the model fits less towards data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) What about the general trend of the variance as λ increases?\n",
    "\n",
    "The variance will decrease as $\\lambda$ increases, because larger $\\lambda$ selects simpler model which lowers the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) What is the bias at λ=0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\lambda=0$, lasso term is zero. The model is linear regression model without regularization. Let true $y=X\\beta+\\varepsilon$, where $\\varepsilon \\sim N(0, \\sigma ^2)$.\n",
    "\n",
    "The bias is:\n",
    "$$\n",
    "\\begin{align*}\n",
    "&E[\\hat{f}(x_0)] - f^*(x_0)\\\\\n",
    "&= E[x_0\\hat{\\beta}] - x_0\\beta\\\\\n",
    "&= E[x_0(X^T X)^{-1}X^T y] - x_0\\beta\\\\\n",
    "&= E[x_0 X^{-1} (X^T)^{-1} X^T (X\\beta + \\varepsilon)] - x_0\\beta\\\\\n",
    "&= E[x_0\\beta + k \\varepsilon] - x_0\\beta\\\\\n",
    "&= E[k \\varepsilon]\\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) What about the variance at λ = ∞?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\lambda = \\infty$, the learned $\\hat{\\beta} = 0$, therefore $\\hat{f}(x) = 0$.\n",
    "\n",
    "The variance is:\n",
    "$$\n",
    "E[\\hat{f}(x_0) - E[\\hat{f}(x_0)]]^2 = E[0 - 0]^2 = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discriminant Analysis\n",
    "**Suppose points in $R^{2}$ are being obtained from two classes, C1 and C2, both of which are well described by bivariate Gaussians with means at\n",
    "$\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}$\n",
    "and\n",
    "$\\begin{bmatrix}\n",
    "2 \\\\\n",
    "2.5 \\\\\n",
    "\\end{bmatrix}$\n",
    ", and covariances\n",
    "$\\begin{bmatrix}\n",
    "2.5 & 1 \\\\\n",
    "1 & 2.5 \\\\\n",
    "\\end{bmatrix}$\n",
    "and\n",
    "$\\begin{bmatrix}\n",
    "2.5 & 1.5 \\\\\n",
    "1.5 & 1 \\\\\n",
    "\\end{bmatrix}$\n",
    "respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) If the priors of C1 and C2 are 0.6 and 0.4 respectively, what is the ideal (i.e. Bayes Optimal) decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes Optimal when Gaussian distribution:\n",
    "$$f(x)=argmaxP(G=k|x)=argmaxP(x|G=k)\\pi_{k}=argmax\\;Gaussian_{k}(x)\\pi_{k}$$\n",
    "\n",
    "When $x$ is classified as $C1$, we have:\n",
    "$$Gaussian_{c1}(x)\\pi_{c1} > Gaussian_{c2}(x)\\pi_{c2}$$\n",
    "\n",
    "Take $\\log$ on both sides and multiply $2$:\n",
    "$$2\\log \\pi_{c1} - \\log |\\Sigma_{c1}| - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1})> 2\\log \\pi_{c2} - \\log |\\Sigma_{c2}| - (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2})$$\n",
    "$$2\\log \\dfrac{\\pi_{c1}}{\\pi_{c2}} - \\log \\dfrac{|\\Sigma_{c1}|}{|\\Sigma_{c2}|} - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1}) + (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2}) > 0$$\n",
    "\n",
    "When above equation is $> 0$, $x$ is classified as $C1$. The decision boundry is when\n",
    "$$2\\log \\dfrac{\\pi_{c1}}{\\pi_{c2}} - \\log \\dfrac{|\\Sigma_{c1}|}{|\\Sigma_{c2}|} - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1}) + (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2}) = 0$$\n",
    "\n",
    "Substitue $\\pi_{c1}$, $\\pi_{c2}$, we have:\n",
    "$$2\\log \\dfrac{0.6}{0.4} - \\log \\dfrac{|\\Sigma_{c1}|}{|\\Sigma_{c2}|} - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1}) + (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2}) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Generate 2 datasets from the known distribution. The first one will have 20 training samples (13 points from C1, 7 points from C2), and 10 test samples (6 and 4 points from C1 and C2 respectively). The second dataset will contain 100 training samples (60 from C1, 40 from C2) and 200 test samples (120 from C1, 80 from C2). What is the optimal Bayes error rate on the two test datasets (i.e., how well does the Bayes optimal decision boundary from (a) do)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define means and covs\n",
    "mean_c1 = np.array([0, 0])\n",
    "mean_c2 = np.array([2, 2.5])\n",
    "cov_c1 = np.array([[2.5, 1], [1, 2.5]])\n",
    "cov_c2 = np.array([[2.5, 1.5], [1.5, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw random samples from C1 and C2\n",
    "samples1_c1_train = np.random.multivariate_normal(mean_c1, cov_c1, 13)\n",
    "samples1_c1_test = np.random.multivariate_normal(mean_c1, cov_c1, 6)\n",
    "\n",
    "samples2_c1_train = np.random.multivariate_normal(mean_c1, cov_c1, 60)\n",
    "samples2_c1_test = np.random.multivariate_normal(mean_c1, cov_c1, 120)\n",
    "\n",
    "samples1_c2_train = np.random.multivariate_normal(mean_c2, cov_c2, 7)\n",
    "samples1_c2_test = np.random.multivariate_normal(mean_c2, cov_c2, 4)\n",
    "\n",
    "samples2_c2_train = np.random.multivariate_normal(mean_c2, cov_c2, 40)\n",
    "samples2_c2_test = np.random.multivariate_normal(mean_c2, cov_c2, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define training and test sets\n",
    "X1_train = np.vstack([samples1_c1_train, samples1_c2_train])\n",
    "y1_train = np.array([1] * 13 + [2] * 7)\n",
    "X1_test = np.vstack([samples1_c1_test, samples1_c2_test])\n",
    "y1_test = np.array([1] * 6 + [2] * 4)\n",
    "\n",
    "X2_train = np.vstack([samples2_c1_train, samples2_c2_train])\n",
    "y2_train = np.array([1] * 60 + [2] * 40)\n",
    "X2_test = np.vstack([samples2_c1_test, samples2_c2_test])\n",
    "y2_test = np.array([1] * 120 + [2] * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Bayes Optimal class that does binary classification\n",
    "class BayesOptimalBinary:\n",
    "    def __init__(self, mean1, mean2, cov1, cov2):\n",
    "        self.mean1 = mean1\n",
    "        self.mean2 = mean2\n",
    "        self.cov1 = cov1\n",
    "        self.cov2 = cov2\n",
    "        \n",
    "        self.cov1_inv = np.linalg.inv(cov1)\n",
    "        self.cov2_inv = np.linalg.inv(cov2)\n",
    "        \n",
    "        self.det_cov1 = np.linalg.det(cov1)\n",
    "        self.det_cov2 = np.linalg.det(cov2)\n",
    "        self.log_ratio_of_cov_det = np.log(self.det_cov1 / self.det_cov2)\n",
    "    \n",
    "    # Define training method to get prior\n",
    "    def train(self, y_train):\n",
    "        self.prior1 = (y_train == 1).sum() / y_train.shape[0]\n",
    "        self.prior2 = 1 - self.prior1\n",
    "        self.log_ratio_of_priors = np.log(self.prior1 / self.prior2)\n",
    "        self.intercept = 2 * self.log_ratio_of_priors - self.log_ratio_of_cov_det\n",
    "    \n",
    "    # Define prediction method\n",
    "    def predict(self, X):\n",
    "        diff_mean1 = X - self.mean1\n",
    "        diff_mean2 = X - self.mean2\n",
    "        \n",
    "        # np.einsum('ij,ij->i', ...): dot product by rows\n",
    "        scores = np.einsum('ij,ij->i', diff_mean2 @ self.cov2_inv, diff_mean2)\\\n",
    "                - np.einsum('ij,ij->i', diff_mean1 @ self.cov1_inv, diff_mean1)\\\n",
    "                + self.intercept\n",
    "        return np.where(scores >= 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to compute error rate\n",
    "def get_err_rate_optimal(mean1, mean2, cov1, cov2, y_train, X_test, y_test):\n",
    "    bayes = BayesOptimalBinary(mean1, mean2, cov1, cov2)\n",
    "    bayes.train(y_train)\n",
    "    y_predicted = bayes.predict(X_test)\n",
    "    return np.sum(y_predicted != y_test) / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of dataset 1 is 0.10\n",
      "Error rate of dataset 2 is 0.07\n"
     ]
    }
   ],
   "source": [
    "# Compute error rates\n",
    "err_rate_optimal_1 = get_err_rate_optimal(mean_c1, mean_c2, cov_c1, cov_c2, y1_train, X1_test, y1_test)\n",
    "err_rate_optimal_2 = get_err_rate_optimal(mean_c1, mean_c2, cov_c1, cov_c2, y2_train, X2_test, y2_test)\n",
    "print('Error rate of dataset 1 is %.2f' % err_rate_optimal_1)\n",
    "print('Error rate of dataset 2 is %.2f' % err_rate_optimal_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Create your own implementation of LDA, which allow the user to pass in the training samples (features and response). Test your implementation on the two datasets from (b). What are the error rates on the training data and test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-ratio of two classes when gaussian distribution with same covariance is:\n",
    "$$\\log \\dfrac{P(G=c1|x)}{P(G=c2|x)}\n",
    "=\\log \\dfrac{Gaussian_{c1}(x)\\pi_{c1}}{Gaussian_{c2}(x)\\pi_{c2}}\n",
    "=\\log \\dfrac{\\pi_{c1}}{\\pi_{c2}} - \\dfrac{1}{2}(\\mu_{c1} + \\mu_{c2})^{T}\\Sigma^{-1}(\\mu_{c1} - \\mu_{c2}) + x^{T}\\Sigma^{-1}(\\mu_{c1} - \\mu_{c2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define method to estimate Gaussian parameters for each class\n",
    "# Class is labeled as integer 1, 2, 3...\n",
    "def estimate_gaussian_params(X, y, same_cov=False):\n",
    "    K = np.amax(y)    # Total K Classes\n",
    "    len_k = [0] * K\n",
    "    mean_k = [None] * K\n",
    "    cov_k = [None] * K\n",
    "    prior_k = [0] * K\n",
    "    for k in range(K):\n",
    "        X_k = X[y == k+1]\n",
    "        mean_k[k] = np.mean(X_k, axis=0)\n",
    "        cov_k[k] = np.cov(X_k, rowvar=False)\n",
    "        len_k[k] = X_k.shape[0]\n",
    "        prior_k[k] = len_k[k] / y.shape[0]\n",
    "    \n",
    "    if same_cov:\n",
    "        cov = np.zeros((X.shape[1], X.shape[1]))\n",
    "        for k in range(K):\n",
    "            cov += (cov_k[k] * (len_k[k] - 1))\n",
    "        cov /= (y.shape[0] - K)\n",
    "        return (prior_k, mean_k, cov)\n",
    "    else:\n",
    "        return (prior_k, mean_k, cov_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define LDA class that does binary classification\n",
    "class LdaBinary:\n",
    "    # Define training method\n",
    "    def train(self, X, y):\n",
    "        prior_k, mean_k, cov = estimate_gaussian_params(X, y, True)\n",
    "        self.prior1 = prior_k[0]\n",
    "        self.prior2 = prior_k[1]\n",
    "        self.mean1 = mean_k[0]\n",
    "        self.mean2 = mean_k[1]\n",
    "        self.cov = cov\n",
    "        self.cov_inv = np.linalg.inv(cov)\n",
    "        \n",
    "        self.diff_mean = (self.mean1 - self.mean2).reshape(X.shape[1], 1)\n",
    "        self.intercept = np.log(self.prior1 / self.prior2)\\\n",
    "                        - 0.5 * ((self.mean1 + self.mean2).reshape(1, X.shape[1]) @ self.cov_inv @ self.diff_mean)\n",
    "    \n",
    "    # Define prediction method\n",
    "    def predict(self, X):\n",
    "        scores = (X @ self.cov_inv @ self.diff_mean + self.intercept).reshape(-1)\n",
    "        return np.where(scores >= 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to compute error rate\n",
    "def get_err_rate_lda(X_train, y_train, X_test, y_test):\n",
    "    lda = LdaBinary()\n",
    "    lda.train(X_train, y_train)\n",
    "    y_train_predicted = lda.predict(X_train)\n",
    "    y_test_predicted = lda.predict(X_test)\n",
    "    \n",
    "    err_rate_train = np.sum(y_train_predicted != y_train) / y_train.shape[0]\n",
    "    err_rate_test = np.sum(y_test_predicted != y_test) / y_test.shape[0]\n",
    "    \n",
    "    return err_rate_train, err_rate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of training set 1 is 0.05\n",
      "Error rate of test set 1 is 0.20\n"
     ]
    }
   ],
   "source": [
    "# # Compute error rates for dataset 1\n",
    "err_rate_lda_train1, err_rate_lda_test1 = get_err_rate_lda(X1_train, y1_train, X1_test, y1_test)\n",
    "print('Error rate of training set 1 is %.2f' % err_rate_lda_train1)\n",
    "print('Error rate of test set 1 is %.2f' % err_rate_lda_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of training set 2 is 0.14\n",
      "Error rate of test set 2 is 0.14\n"
     ]
    }
   ],
   "source": [
    "# Compute error rates for dataset 2\n",
    "err_rate_lda_train2, err_rate_lda_test2 = get_err_rate_lda(X2_train, y2_train, X2_test, y2_test)\n",
    "print('Error rate of training set 2 is %.2f' % err_rate_lda_train2)\n",
    "print('Error rate of test set 2 is %.2f' % err_rate_lda_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Create your own implementation of QDA, similar to the LDA portion. Test your implementation on the two datasets from (b). What are the error rates on the training data and test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-ratio of two classes when gaussian distribution with different covariance is:\n",
    "$$\\log \\dfrac{P(G=c1|x)}{P(G=c2|x)}\n",
    "=\\log \\dfrac{Gaussian_{c1}(x)\\pi_{c1}}{Gaussian_{c2}(x)\\pi_{c2}}\n",
    "=2\\log \\dfrac{\\pi_{c1}}{\\pi_{c2}} - \\log \\dfrac{|\\Sigma_{c1}|}{|\\Sigma_{c2}|} - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1}) + (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define QDA class that does binary classification\n",
    "class QdaBinary:\n",
    "    # Define training method\n",
    "    def train(self, X, y):\n",
    "        prior_k, mean_k, cov_k = estimate_gaussian_params(X, y)\n",
    "        self.prior1 = prior_k[0]\n",
    "        self.prior2 = prior_k[1]\n",
    "        self.mean1 = mean_k[0]\n",
    "        self.mean2 = mean_k[1]\n",
    "        self.cov1 = cov_k[0]\n",
    "        self.cov2 = cov_k[1]\n",
    "        \n",
    "        self.cov1_inv = np.linalg.inv(self.cov1)\n",
    "        self.cov2_inv = np.linalg.inv(self.cov2)\n",
    "        \n",
    "        self.det_cov1 = np.linalg.det(self.cov1)\n",
    "        self.det_cov2 = np.linalg.det(self.cov2)\n",
    "        self.log_ratio_of_cov_det = np.log(self.det_cov1 / self.det_cov2)\n",
    "        self.log_ratio_of_priors = np.log(self.prior1 / self.prior2)\n",
    "        self.intercept = 2 * self.log_ratio_of_priors - self.log_ratio_of_cov_det\n",
    "    \n",
    "    # Define prediction method\n",
    "    def predict(self, X):\n",
    "        diff_mean1 = X - self.mean1\n",
    "        diff_mean2 = X - self.mean2\n",
    "        \n",
    "        # np.einsum('ij,ij->i', ...): dot product by rows\n",
    "        scores = np.einsum('ij,ij->i', diff_mean2 @ self.cov2_inv, diff_mean2)\\\n",
    "                - np.einsum('ij,ij->i', diff_mean1 @ self.cov1_inv, diff_mean1)\\\n",
    "                + self.intercept\n",
    "        return np.where(scores >= 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to compute error rate\n",
    "def get_err_rate_qda(X_train, y_train, X_test, y_test):\n",
    "    qda = QdaBinary()\n",
    "    qda.train(X_train, y_train)\n",
    "    y_train_predicted = qda.predict(X_train)\n",
    "    y_test_predicted = qda.predict(X_test)\n",
    "    \n",
    "    err_rate_train = np.sum(y_train_predicted != y_train) / y_train.shape[0]\n",
    "    err_rate_test = np.sum(y_test_predicted != y_test) / y_test.shape[0]\n",
    "    \n",
    "    return err_rate_train, err_rate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of training set 1 is 0.05\n",
      "Error rate of test set 1 is 0.10\n"
     ]
    }
   ],
   "source": [
    "# # Compute error rates for dataset 1\n",
    "err_rate_qda_train1, err_rate_qda_test1 = get_err_rate_qda(X1_train, y1_train, X1_test, y1_test)\n",
    "print('Error rate of training set 1 is %.2f' % err_rate_qda_train1)\n",
    "print('Error rate of test set 1 is %.2f' % err_rate_qda_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of training set 2 is 0.09\n",
      "Error rate of test set 2 is 0.07\n"
     ]
    }
   ],
   "source": [
    "# # Compute error rates for dataset 2\n",
    "err_rate_qda_train2, err_rate_qda_test2 = get_err_rate_qda(X2_train, y2_train, X2_test, y2_test)\n",
    "print('Error rate of training set 2 is %.2f' % err_rate_qda_train2)\n",
    "print('Error rate of test set 2 is %.2f' % err_rate_qda_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Suppose the cost of misclassifying an input actually belonging to C1 is twice as expensive as misclassifying an input belonging to C2. Correct classification does not incur any cost. If the objective is to minimize the expected cost rather than expected misclassification rate, how would this change the Bayes optimal decision boundary from (a)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a more generalized case, let the cost of misclassifying an input actually belonging to C1 is $k$ times as expensive as misclassifying an input belonging to C2.\n",
    "\n",
    "Let $f$ be the classifier, $f^*$ be the optimal classifier, $y$ be the correct label. $R(f) = E[L(f), y]$ be the risk given loss $L$ as a function of $f$ and $y$.\n",
    "\n",
    "For binary classification, let's use the loss function as follows:\n",
    "$$\n",
    "L(f) = \\begin{cases}\n",
    "1 & f(x) = c1\\;\\&\\;y = c2\\\\\n",
    "k & f(x) = c2\\;\\&\\;y = c1\\\\\n",
    "0 & f(x) = y\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The optimal classifier $f^{*}$ is:\n",
    "$$\n",
    "\\begin{align*}\n",
    "f^{*} &= argmin\\;R(f)\\\\\n",
    "&= argmin\\;E[L(f), y]\\\\\n",
    "&= argmin\\;(P(y=c2|x)\\mathbb{1}_{f(x)=c1} + kP(y=c1|x)\\mathbb{1}_{f(x)=c2})\\\\\n",
    "&= argmin\\;(P(y=c2|x)\\mathbb{1}_{f(x)=c1} + kP(y=c1|x)(1-\\mathbb{1}_{f(x)=c1}))\\\\\n",
    "&= argmin\\;(kP(y=c1|x) + (P(y=c2|x) - kP(y=c1|x))\\mathbb{1}_{f(x)=c1})\\\\\n",
    "&= \\begin{cases}\n",
    "c1 & kP(y=c1|x) > P(y=c2|x)\\\\\n",
    "c2 & Otherwise\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In this case, $k = 2$, so the optimal $f^{*}$ is:\n",
    "$$\n",
    "f^{*} =\n",
    "\\begin{cases}\n",
    "c1 & 2P(y=c1|x) > P(y=c2|x)\\\\\n",
    "c2 & Otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And the decision boundary changes to:\n",
    "$$\n",
    "2P(y=c1|x) = P(y=c2|x)\\\\\n",
    "2Gaussian_{c1}(x)\\pi_{c1} = Gaussian_{c2}(x)\\pi_{c2}\\\\\n",
    "2\\log 2 + 2\\log \\dfrac{\\pi_{c1}}{\\pi_{c2}} - \\log \\dfrac{|\\Sigma_{c1}|}{|\\Sigma_{c2}|} - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1}) + (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2}) = 0\n",
    "$$\n",
    "If $\\log$ is base $2$, then the dicision boundary is:\n",
    "$$\n",
    "2 + 2\\log \\dfrac{\\pi_{c1}}{\\pi_{c2}} - \\log \\dfrac{|\\Sigma_{c1}|}{|\\Sigma_{c2}|} - (x-\\mu_{c1})^T\\Sigma_{c1}^{-1}(x-\\mu_{c1}) + (x-\\mu_{c2})^T\\Sigma_{c2}^{-1}(x-\\mu_{c2}) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spam classification using Naive Bayes and Standard Logistic Regression\n",
    "#### Consider the email spam dataset, which contains 4601 e-mail messages that have been split into 3000 training (spam.train.dat) and 1601 test emails (spam.test.dat). 57 features have been extracted with a binary label in the last column. You can read more about the data at the UCI repository (https://archive.ics.uci.edu/ml/datasets/spambase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) You will explore the effects of feature preprocessing and its impact on Naive Bayes and Standard (unregularized) logistic regression. Preprocess your data in the following ways (they are independent of one another and should not build on each step):\n",
    "**1. No preprocessing.**<br>\n",
    "**2. Standardize the columns so they all have mean 0 and unit variance. Note that you want to apply the transformation you learned on the training data to the test data. In other words, the test data may not have mean of 0 and unit variance.**<br>\n",
    "**3. Transform the features using $\\log (x_{ij} + 0.1)$.**<br>\n",
    "**4. Binarize the features using $\\mathbb{1}_{x_{ij}>0}$ (Note that $\\mathbb{1}$ denotes the indicator function).**<br>\n",
    "**You are free to use any preprocessing module (e.g., sklearn.preprocessing).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Load data from file\n",
    "data_train = np.genfromtxt('spam.train.dat')\n",
    "data_test = np.genfromtxt('spam.test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set features and target\n",
    "X_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1].astype(int)\n",
    "\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing 1: no preprocessing\n",
    "X1_train = X_train\n",
    "X1_test = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing 2: standardization\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X2_train = scaler.transform(X_train)\n",
    "X2_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing 3: log(x+0.1)\n",
    "X3_train = np.log(X_train + 0.1)\n",
    "X3_test = np.log(X_test + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing 4: binarization\n",
    "binarizer = preprocessing.Binarizer().fit(X_train)\n",
    "X4_train = binarizer.transform(X_train)\n",
    "X4_test = binarizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Fit a Naive Bayes model to each of the four preprocessing steps above using only the training data. You are free to use any existing packages. Report the accuracy rate and AUC on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "nb = GaussianNB()\n",
    "fpr_bayes = [None] * 4\n",
    "tpr_bayes = [None] * 4\n",
    "\n",
    "# Define convenience method to calculate AR and AUC, and return ROC for test set\n",
    "def calc_scores(cls, X_train, y_train, X_test, y_test, identifier):\n",
    "    cls.fit(X_train, y_train)\n",
    "    \n",
    "    ar_train = cls.score(X_train, y_train)\n",
    "    ar_test = cls.score(X_test, y_test)\n",
    "    \n",
    "    auc_train = roc_auc_score(y_train, cls.predict_proba(X_train)[:, 1])\n",
    "    y_positive_prob = cls.predict_proba(X_test)[:, 1]\n",
    "    auc_test = roc_auc_score(y_test, y_positive_prob)\n",
    "    \n",
    "    print('Accuracy Rate on training set %s is %.2f' % (identifier, ar_train))\n",
    "    print('Accuracy Rate on test set %s is %.2f' % (identifier, ar_test))\n",
    "    print('AUC on training set %s is %.2f' % (identifier, auc_train))\n",
    "    print('AUC on test set %s is %.2f' % (identifier, auc_test))\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_positive_prob)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 1 is 0.83\n",
      "Accuracy Rate on test set 1 is 0.82\n",
      "AUC on training set 1 is 0.95\n",
      "AUC on test set 1 is 0.94\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 1\n",
    "fpr_bayes[0], tpr_bayes[0] = calc_scores(nb, X1_train, y_train, X1_test, y_test, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 2 is 0.82\n",
      "Accuracy Rate on test set 2 is 0.81\n",
      "AUC on training set 2 is 0.89\n",
      "AUC on test set 2 is 0.88\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 2\n",
    "fpr_bayes[1], tpr_bayes[1] = calc_scores(nb, X2_train, y_train, X2_test, y_test, '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 3 is 0.82\n",
      "Accuracy Rate on test set 3 is 0.82\n",
      "AUC on training set 3 is 0.95\n",
      "AUC on test set 3 is 0.95\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 3\n",
    "fpr_bayes[2], tpr_bayes[2] = calc_scores(nb, X3_train, y_train, X3_test, y_test, '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 4 is 0.80\n",
      "Accuracy Rate on test set 4 is 0.80\n",
      "AUC on training set 4 is 0.95\n",
      "AUC on test set 4 is 0.94\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 4\n",
    "fpr_bayes[3], tpr_bayes[3] = calc_scores(nb, X4_train, y_train, X4_test, y_test, '4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Fit a standard (no regularization) logistic regression model to each of the four preprocessing steps above using only the training data. You are free to use any existing packages. Report the accuracy rate and AUC on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgr = LogisticRegression(C=1e9, warm_start=False)   # Set inverse of reg strength to large number\n",
    "fpr_lgr = [None] * 4\n",
    "tpr_lgr = [None] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 1 is 0.93\n",
      "Accuracy Rate on test set 1 is 0.92\n",
      "AUC on training set 1 is 0.98\n",
      "AUC on test set 1 is 0.97\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 1\n",
    "fpr_lgr[0], tpr_lgr[0] = calc_scores(lgr, X1_train, y_train, X1_test, y_test, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 2 is 0.93\n",
      "Accuracy Rate on test set 2 is 0.92\n",
      "AUC on training set 2 is 0.98\n",
      "AUC on test set 2 is 0.97\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 2\n",
    "fpr_lgr[1], tpr_lgr[1] = calc_scores(lgr, X2_train, y_train, X2_test, y_test, '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 3 is 0.95\n",
      "Accuracy Rate on test set 3 is 0.94\n",
      "AUC on training set 3 is 0.99\n",
      "AUC on test set 3 is 0.98\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 3\n",
    "fpr_lgr[2], tpr_lgr[2] = calc_scores(lgr, X3_train, y_train, X3_test, y_test, '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate on training set 4 is 0.94\n",
      "Accuracy Rate on test set 4 is 0.93\n",
      "AUC on training set 4 is 0.98\n",
      "AUC on test set 4 is 0.98\n"
     ]
    }
   ],
   "source": [
    "# Show AR and AUC scores on preprocessed data 4\n",
    "fpr_lgr[3], tpr_lgr[3] = calc_scores(lgr, X4_train, y_train, X4_test, y_test, '4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Plot the receiver operating characteristic (ROC) curves derived from the test data for each of the eight models (4 Naive Bayes, 4 logistic regression models). Comment on how the models compare with one another with regards to ROC, AUC, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to plot ROC curves\n",
    "def plot_roc(fpr, tpr, identifier):\n",
    "    ax = plt.gca()\n",
    "    lineObjects = [ax.plot(fpr[i], tpr[i], label='dataset '+str(i+1)) for i in range(len(fpr))]\n",
    "    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic for ' + identifier)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXd4VMXawH/v7qZ3ktB7rwLSBGmKiCI2VCzY9dqwXi6fXvXasV/LvYrYveL1UkRRigVUsNJLQGoAlVADJJuebJnvj3MWlpCySXazm2R+z7PPnjMzZ+Y958yZd+o7opRCo9FoNJrysARbAI1Go9GENlpRaDQajaZCtKLQaDQaTYVoRaHRaDSaCtGKQqPRaDQVohWFRqPRaCpEK4paQkQmisg3wZYjlBCRPBFpH4R024qIEhFbbacdCETkNxEZWY3rqpUnRSRKROaLiF1E5lT1+kBQ3Weg8Y0GqShE5HcRKTQLqgMi8oGIxAYyTaXUf5VSZwcyDW9EZIiIfCciueYHPV9EutdW+mXIs1REbvZ2U0rFKqV2BSi9ziIyR0QOm/efJiJ/FRFrINKrLqbC6liTOJRSPZRSSytJ5yTlWIM8eSnQBEhWSl1WjetLyzbSlG1aKfefROR6X+Lw5RlUQy7PM8szfwdFZJqIhPkznbpAg1QUJucrpWKBPkBf4O9BlqdalFUrFpHBwDfA50BzoB2wAfg5EDX4UKuZi0gHYAWwB+illEoALgP6A3F+Tito9x7EtNsA25VSzqpeWIHM+cA1ItK2BnIFikSzrOgFDAYmBVme2kcp1eB+wO/AWV7nzwMLvc4jgBeBP4GDwHQgysv/QmA9kAPsBM4x3ROAd4H9wF7gKcBq+l0P/GQevwG8WEqmz4G/msfNgblAJrAbuNsr3GPAJ8BHZvo3l3F/PwLTynD/EvjQPB4JZAAPAofNZzLRl2fgde39wAFgBpAELDBlzjKPW5rhpwIuoAjIA14z3RXQ0Tz+AHgdWAjkYhT0HbzkORvYBtiBacCysu7dDPuR9/ssw7+tmfZ15v0dBh7y8h8I/Apkm+/yNSDcy19hFBY7gN2m26sYiikHWAMM8wpvNZ/zTvPe1gCtgB/MuPLN53K5GX4cRv7KBn4BTimVd+8H0oBiwIZXfjZlX23KcRB4yXT/00wrz/wNxitPmmF6AIuBo+a1D5bx7B4HSgCHGc9NGBXOh4E/gEPAh0BCqWd9kynDD2XEORIjP/0beN/L/SfgevO4A/AdcMR8X//FKMBP+KYxvp1CoJGXX1/zmjDz/EZgC0Y+/RpoU0k+sZUqK97yOn/A671uBi423cPN59jLK2xjoABI9eE9349RhuRi5PtRQS0zg5l40G76xA+rJbAReNXL/2XgC6ARRg10PvCM6TcQo7AabX4gLYCupt9nwJtAjJkpVgK3mn7HPkpgOEahIuZ5kpm5m5txrgEeMTNbe2AXMMYM+xjGR3qRGTaq1L1FYxTKZ5Rx3zcA+83jkYATeAlDKYzAKLC6+PAMPNc+Z14bBSQDl5jpxwFzgHleaS+lVMHOyYriiPl8bRgFwUzTLwWj4Btv+t1jPoPyFMUB4IYK3n9bM+23Tdl7YxS63Uz/fsBpZlptMQqVe0vJvdh8Nh7lebX5DGzAZFOGSNNvCkYe6wKImV5y6WdgnvfFKGwHYSiY6zDya4RX3l2PoWiivNw8+flX4BrzOBY4rdQ9exd613M8T8ZhKMXJQKR5Pqic5/cY8JHX+Y1AOkZejQU+BWaUSvdDjO8iqoz4RmIoiqbme/bkQW9F0RHjm4sAUjGU7CvlfNPfAX/x8nsBmG4eX2jK2s18Vw8Dv1SST2zmeXOMlvmNXmEu4/h3eznGN9TM9JsGPOcV9h5gfmXvGSOf7AGae8nRoSwZa63MDGbiQbtp44XkYWhrBXyLWTvB+JDzObE2O5jjNcc3gZfLiLMJRmHj3fK4EvjePPb+KAWjdjXcPP8L8J15PAj4s1Tcf8esaWF8pCfVyrzCtjTvqWsZfucADvN4JEZhH+PlPxv4hw/PYCRGrTKyAjn6AFle50upXFG84+U3FthqHl8L/OrlJ+aHVJ6icGC28srxb2um3dLLbSVwRTnh7wU+KyX3mZXksSygt3m8DbiwnHClFcUbwJOlwmwDRnjl3RtL+f/O8ULyB4xaf0o591yeorgSWOfj9/MYJyqKb4E7vM67mO/A5pVu+wriGwlkmMfPA7PM42OKooxrLvKWt9QzuJnj35Mnr3i+tS+Bm7yus2DU8ttUkE+yzZ/CqPnHV3Av6z3vGvNb5niFcDUwobL3jKEUD2G0kMJ8eSeB/jXkMYqLlFJxGJm0K0atFYzaSjSwRkSyRSQb+Mp0B6Mmt7OM+NoAYcB+r+vexGhZnIAycsVMjI8T4CqMGrQnnuaeOMx4HsRQRB72VHBfWYAbaFaGXzOMJvixsEqpfK/zPzBqR5U9A4BMpVSR50REokXkTRH5Q0RyMAqsxCoOHh/wOi7AqJ1iynTsns3nl1FBPEco+/59Ss8cCF9gTnTIAZ7meP7wcMI7EJG/icgWc+A8G6Mb0nNNeXmmLNoAk0u9/1YYz6DMtEtxE9AZ2Coiq0RknI/pVkXG0jTHyDse/sBQEr7mWW+eA8aISG9vRxFpIiIzRWSv+U4+4uR34mEuMFhEmmG03t0Y3bFgPN9XvZ7tUQxl0qICmVKUUokY38TPGN1VHrmuFZH1XvH19MillFqBka9GikhXDAXwhZccZb5npVQ6RuXkMeCQed/e77/WaciKAgCl1DKM2uyLptNhjG6gHkqpRPOXoIzBLDAyfIcyotqD0aJI8bouXinVo5yk/wdcKiJtMGoec73i2e0VR6JSKk4pNdZb7AruJx+j+6Gs2SgTMGp/HpJEJMbrvDWwz4dnUJYMkzFqkoOUUvEYHygYH2GFMvvAfoyWkhGhiHifl8ESjG6w6vIGsBXoZN7Lgxy/Dw/H7kdEhgH/h/F8k8xCxe51TXl5piz2AFNLvf9opdT/ykq7NEqpHUqpKzEqKM8Bn5jvuLLnvwej66g67MMo+Dy0xmitHvQWzZeIlFJHgFeAJ0t5PW3G0ct8J1dz8jvxxJGFMZnjcoxK2EyzcgHGfd5a6vlGKaV+8UG2Qoyy4jQRSTG/3beBOzG6EhOBTaXk+o8p6zXAJ16Vqwrfs1LqY6XUUIznqjDeZdBo8IrC5BVgtIj0Vkq5MV7+yyLSGEBEWojIGDPsu8ANIjJKRCymX1el1H6MzPlPEYk3/TqIyIiyElRKrcMokN8BvlZKZZteK4FcEbnfnK9uFZGeIjKgCvfzAHCdiNwtInEikiQiT2F0Hz1eKuzjIhJuFnbjgDk+PIOyiMNQLtki0gh4tJT/QapfEC0EeonIReasmUkY/dnl8SgwREReEJGmpvwdReQjEUn0Ib04jL7yPLMmeLsP4Z0YA/k2EXkEiPfyfwd4UkQ6icEpIpJs+pV+Lm8Dt4nIIDNsjIicJyI+zdYSkatFJNV8h5485TZlc1P+O1gANBORe0Ukwsw3g3xJE6PSc5+ItBNjmvnTGN1HVZ4VZfISMARjHMFDHEZ3sV1EWmCM+1TExxhdlpeaxx6mA38XkR4AIpIgIj5N8RWRCIwC/wBGq9WjgDNN/xswWhTefARcjKEsPvRyL/c9i0gXETnTTK8I47ty+yJjoNCKAlBKZWK8xEdMp/sxBryWm83cJRi1ZZRSKzEGhV/GqDUu43ht6lqMAejNGF1An1BxF8jHGP2QxzKyUsqFUWD3wZjx5FEmCVW4n5+AMRiDv/sxugL6AkOVUju8gh4w5dyH0fV1m1Jqa2XPoBxewRgYPgwsx+iq8uZVjBZUloj8y9d7Me/nMEYL6XmMD7Q7Rn9vcTnhd2IoxbbAbyJix2ixrcYYl6qMv2HURHMxPuhZlYT/GuN+t2M86yJO7Gp5CWP85xsMBfQuxrMCo3vhP2b3wwSl1GqMMavXMN5NOsZYgq+cg3HPeRjP/AqlVKFSqgBj9tnPZlqneV+klMrFGCw+HyNf7ADO8DHN9zBmvv2AkWeLgLuqIPMJKKVyMN51Iy/nx4FTMb65hRgD5hXxBdAJOKCU2uAV92cYtfOZZr7eBJxbSVzZ5vM8iJGvLlAGm4F/YrTgD2JMn/251L3sAdZiKJQfvdwres8RwLMY39IBjNZhUKfvewZZNA0MMVaxfqSUqqgLJyQREQvGGMVEpdT3wZZHo6kIEXkP2KeUejjYslSXkFoopdGUh9nttQKjGT4Fox94eVCF0mgqQYwFhOMxWvR1Ft31pKkrDMaYlXMYo3vkInNwUaMJSUTkSYyurReUUruDLU9N0F1PGo1Go6kQ3aLQaDQaTYXUuTGKlJQU1bZt22CLodFoNHWKNWvWHFZKpVYe8mTqnKJo27Ytq1evDrYYGo1GU6cQkT8qD1U2uutJo9FoNBWiFYVGo9FoKkQrCo1Go9FUiFYUGo1Go6kQrSg0Go1GUyFaUWg0Go2mQgKmKETkPRE5JCKbyvEXEfmXiKSLSJqInBooWTQajUZTfQK5juIDDBO6H5bjfy6GGeBOGBv3vGH+azQajaYMPCaXlDq+E9QxN9MdwOVy4nI6UC4nblcJbqejRukGTFEopX4wLSeWx4XAh+bOU8tFJFFEmpkbAGk0DY5ip4vfDxewcvcRjE38DBak7SPM6r/Gv6cwUSizxDF+gtv4uY1/UFhwI0ohuLAoNy5VjEsKsaBAuREUiiKyrLsMN5QZ3jzGE7eXm/e5V1jP9cYePcY+PWIeK1Mej78c28entJ8y3Yx4lSgiil2EOY+H8xSrgqLDH0VY3MeK3GPPRQAlx90V0PiIiyZHXDitxzdtFAViJivmuXHMMT9RJ4Y99isV5nhYH8IBFk9ayjj2+HnnFKVgSV5LluTVbDeBYK7MbsGJm7tkmG4nKQoRuQW4BaB169a1Ipym4aKUIiOrEIfLzfJdR7EXGrWxxZsP4FYgZW7AWTbR7nw6OHdwfd47OAijnN07AcgvMTaE62GGErOg7mMWotFhggWjQLdgFNIWs7A23FTF7qabJwwo9tssfB8dhaMcsebFxhLvNgplp8DmiIhK7zkhXxFdVGkwvyJm4e4pQD3nrQ/BnZ/71/DpvsbgtGIqE1AiKDNxJaa6Md09QiksJ4TxZCJ1Qjg55qcALKY7ciyM8W+EEwRlMc69rzXCW8jMi+T9X7uybl8KrRvl1eie64QJD6XUW8BbAP3799fmbjV+586P17Jlfw4iQvqhij+qYZ1STjiPcBfS3PEnVlwMLPgBh4TTv/AnAJo7M04ImxbZr9x4bVYIt1loFBVGZJ4bpQSjfigUbsvFYrMcKwiMwsFiHgMIbjHaBIjgQJHtdh7XaiIUKTd7XYVYTbcNJUcqfS6DAbDQIszYYPHOLflEYCXMasVb6QlCtDUcd14hyl5Qaby1TeKllxDZo0eZWj5m6FAsPihAAEtMDN2io/0tnt9RStG//9tsP3qYf/7zDO6+exBhYS9WO75gKoq9QCuv85amm0bjd0qcbt5ctpNDucWIgL3QwfwN+xgYvZ8UsXPAcYSYsHy6NY2nXzwUOV30ap6ACLRMiiY63AqAzWrhWEM49wDs+AbLzt2E7QnDkmflQJgViwjpR4SEwxYOhrU0an0WG0VuB8LBCuXMB1Ru+dsjO60+3nAZ1alwoJ3XuadtbrVYkQpaOkbhmm8cOxyAg7hzzik3uDs/n5ghQ7ClpJQbpjaxxMYQO2IEYqn/kzx/+WUPvXo1Ji4ugnfeOZ+UlGhatfJ5F+VyCaai+AK4U0RmYgxi2/X4hKaqKKVwuB38um85xa5ith/MpbDEBcDveb+R68jigL2IrOyj9JetJEo+LoQNkRHEd7GwWyl2AwVmIbJbGV0WNoGsVYowF1hdMHyTIj/yeLpxhdB3l8ItYFGJx9yTzJ2wbW4hvESxsrON4nCzm0HZcKNoFeddPzqZI4CtxMkfg9occ3OFW8nskoqqQmEXExbDoGYnzg9JjkymR0oPn+PQ1A2OHCnggQeW8M4763j00RE89thI+vZt5rf4A6YoROR/wEggRUQygEeBMACl1HRgETAWY1PxAuCGQMmiqZsopcgpyTl2Xuwq5pd9vxyb5TE/fTGrDv1Y3uXHaOlwkBIFjoMQfiicdgfCGZivKBE3zSyRYItCiYXEfIjanVlhXO4mplJwK1RcCapbO5wtWuDu1QVXn66EJSfRtVFXosOM7olu1bx3jcYXlFJ8+OEG/va3xWRlFTJlyhCmTBni93QCOevpykr8FTApUOlr6g6ZBZn8uv9Xlu1ZRmZhJlYx+ldWH/TNnHzLYgvDCooYX3Dk2KwRAEd8a5qqMKIik7CvicS+bJvHB4CI7mYx7pksEwnulhFEnzaIsGbNwOUm7uzRIIIlIoKwNm1OmI2k0QSb++9fwgsv/MKQIa2YPv08evVqEpB06sRgtqZ+4XQ72WXfxeGCw7yy9hW2HN1ygn//Jv1xu90Mc3ZDlRQz6nAzkrZ+A4AFRRuHMTvIgRWnpRHJ0eFYJBpxRkNqF7BFQONuOA/lk/3zL2TjwLHPMMXf4tVXierZA2ujRliiomr3xjUaP1BY6CA/30FKSjQ33dSXTp0acdNNp2KxBK4SU+f2zO7fv7/SGxeFFvmOfLYe3Vquf1ZBCVsOZZCes5Gs4kzWHfmJQVvddN57PO8NzE+kcXoOlqgwYwqq3X/zKyN79sQSE0PKbbcSM3iw3+LVaGqbr75KZ9KkRfTp05S5cydU6VoRWaOU6l+ddHWLQlMlsouyWb5vLZ9v+xancnAop4hdxd/T4rCicfbxgv/8FYr2BxVOC8QBA82fh/hC41/ZFFYUyn0U5RbCE4qwRrkhEZRDSOjgwIITW7NI1pw/j/69uhEZZvG9C0hEdxdp6jz79uVy771fMWfOZrp0SebOOwfUavpaUWhOosjhYm92IRsz7Gzca2dvViER7mI65q3iy6IvOZhgrA2ILIGBu6CzcnHjwrLjKu5ahNMSDgjRQKLLhcsWRUl0E8JPaYatRTwAFlchu/v/A1dYLADdmsXTKCb8hLiGB+qGNZoQ5ttvd3HxxbMoKXHx5JNnMGXKECIiarfo1oqinqKUwm234y4sRDkcJ/9KTjzPzy/EUVTM3I8X0zR7PzaLixbWvZwS5uS0Emh5wGgtnFVBmnF9W5E8uhs4S6BFf8I7dcXaYRBYfctmgRmG02jqJg6Hi7AwK717N2Xs2E489dSZdOzYKCiy6DGKOohyudjz3/cotmcBcLToKEeLjiJA8s/bsBaVEH40D6tpEqI6pDcFt9eU/cQSYU8LG6p1c3o16masBYiMR8LDiRk2DLFYCGvVqkEsatJoAklOTjH/+Md3rFixl59/vhGrn+x86TGKOohSihmbZ5BVnFVp2LSD67Hs+IMwsTF4uZ1T1+YYBsFM4s2fhxIrLOonHI2zUBABTouxordDSheUzYrbJrisFlw2Yde+DFpZ9+OyGorBZYXiCChISKK9LZ4RQx9kaOszdT+/RhNglFJ88slm7rnnKw4cyOOOOwZQXOwiOjr4lS+tKGqJw4WH+XDBVGJzSthydAsH8w8SUwRdMxQ2VXZGsLkgKVfxt50nmnTISYlib7s4XLdcSWyKsfqyTUJr2sYbBhokIoIupQr2MEsYVouxPmHzvhxmrvqTUzL+y2MsAhcUjXyKyISm0HoQxLcAi6+2IjQaTU3JzMznuuvm8eWX6fTt25TPP7+CAQNaBFusY2hF4Qecbie/7vuVIteJUzotOfnEzluGbWcG0cs3ca7pPsw7kAjWxHjKxGrF1jiVsDOaYomJIeH8cWCxEt2/H4OqsAZgV2YeWw9k8dm6vSzefJBEcvkh4j7ixTDeltH7HloOu8v3G9ZoNH4lPj6Cw4cLeOWVMUyaNBCbLfitCG+0oqgBWUVZLN2zlEd+eeQkv3473Nz/yfGWQFYMHGkcydBJTxDRrPkx94hOnbDGl6MoakiRw8XCtP1MnrOBDrKXUy07mBv+Pf0sO44H+st3tGxRvkVTjUYTGH744Q+mTv2RuXMnEBsbzvLlNwd00VxN0IrCB7KLsll3aB0rD6xk9cHVRNuiKXAWnLDIrEl0E/7d/2nk++WoWfPhD9O89LCBWB68i+aNUhgc738TEAvT9nMgx2jJrPszi/32IqxmZlu3+xBP295hTvgBBli2n3jhiAdg2GSwhZeOUqPRBJDDhwuYMmUxH3ywnrZtE/n992x69mwcskoCtKKoEIfbwYr9K7h9ye0nuHdK6kRiRCI9k3syoNkAJnadSGpkCrsvvJCS9J0ASGQkqXfdSfJNN/lFloISJ38cMbqKlmw+yIK0/RQ4nOw5WkgiuTSVLFpIJiMsO2mWFEsT536GR3577HrV5nSk3QjocxXEpEJYZHlJaTSaAKCU4v331zNlymJycor5+9+H8vDDw4mODgu2aJWiFUU5KKWYtGQSv+7/FYCz25zNDT1voFNSJyKsJ29ykr98BSXpO2ny0EMkjr8YS0xMtdI9nFfMl5sO8P7Puyl2uPHMNt1ztPCEcGMsq3gyeha2GAeNXKUsnuZ6HbcdBhM+RKKDM/9ao9Ec56OP0ujePZXp08+jR4/GwRbHZ7SiMMkryWPtobVM3zCdHVk7ThiYnjZqGoObD8ZmOfFxOQ4coGiLYdAu4/Y7wGol8bJLsUQatXWlFCt2HyW/2IlSMGv1HrYdyCWnqPyNzrMLjvud27MpUWHG7KP+bSAu0saQDskAjPjxJaIKFLQ/C1I6Q3IHQCCpLTTtdTxCPa1VowkaBQUOnn76R267rT8tW8Yzd+4EEhIiQ7qbqSy0ogB+2vvTSd1LEzpPoMhVxK2n3Err+BP36XYXFbGtT9+T4ikIj+KS99aQV+Qkv9jJvjIM27VIjOLC3s1PcveggMZxEVw+oDWpceVsz3h0NxxcDWc9BkPvq+z2NBpNEFi0aAeTJi3i99+zadEijttvH0BSUt20WNzgFcXc7XN57NfHAOjXpB9T+k+hXUK7YxvPlMaVnc2BqU8fO//qrGtZ5EhCiXCkcSt6RthoEhdJbKSN2AgbFhHO7dWUCJsFq0Xo1jS+5rWJjZ8Y/z0vrVk8Go3G72Rk5HDvvV8xd+4WunVLYdmy6xk+vE3lF4YwDVpRbDmy5ZiSuPfUe7mpV8UDz/sefAj7p58eO7/w/GcosYbRp1UikWEWvr75tGMzjgKGUpA2C9oMhcSKt9TUaDS1z9SpP7Bw4Q6efvpMJk8eQnh43V+82qAVxfub3gfgzdFvMqT5ydsHHsopMrqPXC7yH3mIRiuXATC914XsTGhOeHQUWx89u3b7G/etgyM7YMidtZemRqOpkJUr9xIVZaNXryY89dSZTJlyOu3bJwVbLL/RYBVFobOQL3//EjB2VPPG4XJz76z1pP28nr+v+oh2OfvxjBbMuehujnY6lVfO70HHxrG1LDWwcQ5Yw6H7hbWftkajOQG7vYgHH/yWN95YzbhxnfniiytJTo4mObnsruu6SoNTFEcKj7B8/3I+2W7081/Q4QLCrcaiM7dbsXjLQV5evJ2tB3K5dfevtMvZT8GZ5yBuN2G3380jvTsET3iX0xif6HQ2RNWf2opGU9dQSjFr1m/cd9/XHDqUz113DeTJJ88MtlgBo0EpikMFhxg1Z9Sxc4tYuKb7NQDkFzvp8ejXAMSWFDBr5xwSCw4jqSn0m/ZyUOQ9id3LIP8QnHJ5sCXRaBo0H32UxrXXzqN//+YsWHAl/fqVP5OxPtCgFMWGzA0ATOw2kYldJ9Iq3hgMLnG6ueH9VQCM4RD3LnoeADeQdO01QZG1TNJmQ0SC0aLQaDS1SnGxk127sujWLZUJE3rgdLq59treftsvIpRpUIrCw/hO448pCYD5G/ax8vejXNqvJfdt30AOkDB+PM2mPhU6+zCU5MPWBdBzvDa/odHUMt9/v5vbb19IQYGDHTvuIiLCxg03nLyWqr7SoBTF/J3zy3T/OT2TmzYv5LJvVpBTYNhTavqPh0NHSQBs+xJK8qDXhGBLotE0GA4dyudvf/uGGTPSaN8+ibfeOr/W96sOBRrEHRe7irliwRWkZ6cD0C6h3TG/zNdf5y//fg0wVkXHjR5NwsUXY6nCfg+1QtpsY0OhNqcHWxKNpkGQnn6UgQPfJi+vhIceGsZDDw0jKir0DfgFggahKOzFdtKz02kc1Zj/nPsfwizGyz74wgscffc9ALb0Hs55zzxARPt2FUUVHPIPQ/oSY+2E3pNaowkoOTnFxMdH0KFDEjfd1Jcbb+xLt26pwRYrqDSIUmfj4Y0A3Nn3TlrGtQTg6B97jymJ/110D2M/mhaaSgLgt89AufRsJ40mgOTnl3D//Ytp2/YVMjJyEBFeeOHsBq8koIEoirfS3qJxVGPObG3Mcy5yuHji0/UALB11FZMfuYnIsBBeZp82Cxr3gCY9gi2JRlMvmT9/G927T+P5539h/PhudWKPiNqkQXQ9HSk8wuDmg0mISMDhcjP0ue8IP5DJrcCVZ/UiIZQzxdFdkLEKzno82JJoNPUOp9PNhAlz+OyzrfTokcqPP97A0KGtK7+wgVHvFYVSiuzibJIijZXML3y9jcN5Jbxo/QMAS2Q5prxDhbQ5gEAvbSlWo/EXSilEBJvNQrNmsTz77Cjuu29wvTDgFwjqfddTobOQYlcxiRGJPDF/M2/9sIvbO9jo8fVMAGLPDOFl90rBxtnQdigktAy2NBpNvWD58gz693+btWv3A/D66+dx//1DtZKogHqvKLKKswAIl3je+3k3jeMiuOCf9wKQcNFFWCJCuEWxby0cSYdelwVbEo2mzpOVVcjtty9gyJB3OXgwj6yswsov0gABVhQico6IbBORdBF5oAz/1iLyvYisE5E0ERnrbxmyigxFYXHHYlFuHh/YCEt8PJa4OJo/+4y/k/MvadpSrEbjD2bN2kTXrq/z1ltruffe09iyZRKjRrUPtlh1hoCNUYiIFXgdGA1kAKtE5Aul1GavYA8Ds5VSb4hId2AR0NafcngUhcsRxfzP78DyuTJsOF0TQjacysLlhE2fQOcxEJUYbGk0mjrN1q2Hads2ka++mkjfvs2CLU6/KE7XAAAgAElEQVSdI5AtioFAulJql1KqBJgJlK4aKyDePE4A9vlbCE/Xkys/DAsKgGbPPEPKLX/xd1L+ZfdSyM/Uayc0mmpQVOTk8ceXMn/+NgAefHAYv/xyo1YS1SSQiqIFsMfrPMN08+Yx4GoRycBoTdxVVkQicouIrBaR1ZmZmVUSIqsoizCHImqtkWHi7r6XxIsvwpYa4oto0mZDpLYUq9FUlSVLdnHKKW/w2GPLWLbMmN0YFmZtEFZeA0Wwn9yVwAdKqZbAWGCGiJwkk1LqLaVUf6VU/9QqFvBZRVmclSb0nv4CANGNEvwgdoApyYctC6D7RWAL4cF2jSaEOHgwj4kTP2X06BkoBd98czUvvqgrWv4gkIpiL9DK67yl6ebNTcBsAKXUr0AkkOJPIbKLszn1T2Pa29NjJ5N0WR2YQbR1ETjy4RRtKVaj8ZXFi3fxySebeeSR4WzceDujRwdxN8p6RiAX3K0COolIOwwFcQVwVakwfwKjgA9EpBuGoqha31IlFB7cT++txQDkte2EWOvAXOmNsyG+JbQeEmxJNJqQZsOGA+zYcZRLL+3OxIm9OP30VrRrp7cJ9jcBa1EopZzAncDXwBaM2U2/icgTInKBGWwy8BcR2QD8D7heKaX8KYcj6ygAX/c7j+SEGH9GHRjyMiH9W2MltrYUq9GUSV5eCZMnf02/fm/xwANLcDrdiIhWEgEioCY8lFKLMAapvd0e8TreDAR0g4UzPtkJwLboxqTGhQcyKf+gLcVqNBUyb95W7rrrSzIycrjlllN55pmzsNl0pSqQ1OunW7BuHR13Gasvf41rS2psHRgYTpsFTXpCk+7BlkSjCTk2bjzIxRfPIikpkp9/vpE33zyfRo1CbJOxeki9VhQHpk4FYP1fziA7PIaUuBBXFEd2wt7VehBbo/HC4XDx3Xe7AejVqwkLF17FmjW3MGRIq0qu1PiLeqso3MXFFG/6DYB9p/cHCP0WxUbTUmxPbSlWowH45Zc99Ov3FqNHzyA93RhvHDu2E2GhvH9MPaTeKoqClSsBeHuMBXHHApAayi0KpYxFdm2HQkLpdYkaTcPi6NFCbrllPqef/h7Z2UV8+ukEOnZsFGyxGiz1dj8K5XACkN5MaOow+jBTQrlFsXctHN0JQ+8NtiQaTVApKnLSp8909u3LZfLkwTz22EhiY+vARJR6TL1VFMXp6QDkRENJSTRQFNotio2zwRoB3S6oPKxGUw/JyMihZct4IiNtPPnkGfTp05TevZsGWywN9bjrqXjrFoqbNuJIglBQGEFUmJWYiBDViy4nbJqrLcVqGiSFhQ4eeeR7OnT41zEjftdd10criRDCp5JTRMKB1kqp9ADL41dcFmPtXk5eBKlxjiBLUwG7lmpLsZoGyTff7OSOOxayc2cWV199CgMH6vG5UKTSFoWInAdsBBab531E5LNAC1YTnFlZFKxeQ2FsGLFhsRzNd4V2t1PaLNNS7OhgS6LR1Bp33bWIMWM+wmIRliy5hhkzLqZJk9hgi6UpA19aFE8Ag4DvAZRS60WkY0ClqiH5P/2E89AhVlw3hKTI/WQeKKZ9aoia7yjOg60LjLUT2lKspp7jcrkBsFotnHZaS1JSorn//qFERoZot7AG8G2MwqGUyi7l5ld7TP5GuVwAHIgqISkiicN5xaHboti2CBwF0EsvstPUb9au3c/gwe8ybdoqACZOPIVHHx2plUQdwBdFsUVEJgAWEWknIi8DywMsV41QJSUAHHXlkhCRSFaBI3SnxqbNhoRW0HpwsCXRaAJCbm4x9933FQMGvM2ff9pp1iwu2CJpqogviuJOoB/gBj4FioF7AilUTXHZ7QDss+QQZTV2Wg3JFkVeJuz8Dnpdpi3Fauol33yzk27dXufVV1dw66392Lr1Ti69VNsxq2v40uYbo5S6H7jf4yAi4zGURkjittuRsDAOubLpY27JHZLmO3771LQUq7udNPWT8HArjRvHMHfuBAYNahlscTTVxJdq7MNluD3kb0H8icuegyUhnhLlwKKMQeyQNAiYNgua9oLG3YItiUbjFxwOF8899xMPPfQtACNHtmX16lu0kqjjlNuiEJExwDlACxF5ycsrHqMbKmRx2e2ouFjAjnIZiiLkWhRHdsLeNTD6yWBLotH4hZ9++pPbblvAb79lctll3XG7FRaLYLFIsEXT1JCKup4OAZuAIuA3L/dc4IFAClVTXHY7rjjDvpOjJBoIwTGKtNmAGDvZaTR1mCNHCrj//iW8++46WrdOYP78Kxk3rnOwxdL4kXIVhVJqHbBORP6rlCqqRZlqjMtupyTJMCJWVBxFXISNyFAyS6yUYdup3TCIbx5saTSaGnHkSCEzZ27i//5vCI88MoKYGG3Ar77hy2B2CxGZCnQHIj2OSqmQrTK4cuwUtzAK4PzCiNBrTexdA0d3wbDJwZZEo6kWW7ZkMnv2bzz66Eg6d07mzz/v0zvN1WN8Gcz+AHgfEOBcYDYwK4Ay1Rh3tp2CKOPW7HnhobeGIs1jKfb8YEui0VSJggIHDz30Lb17T+fVV1eQkZEDoJVEPccXRRGtlPoaQCm1Uyn1MIbCCElUSQnuggJyI8FmsXE0zxJaLQqXw7AU2+Vcw76TRlNH+OqrdHr2nMbTT//EVVf1Ytu2O2nZMj7YYmlqAV+6nopFxALsFJHbgL1AyC6tdOUYNRx7hJOkiCQyc0tI6RhCfaY7v4eCw3rthKZOkZdXwjXXfEZychTff38dI0e2DbZImlrEF0VxHxAD3A1MBRKAGwMpVE3wKIqscAcJEYnsKnKGVoti42yISoKO2lKsJrRxudz873+buPLKnsTGhrNkyTV07ZpCRKju66IJGJW+caXUCvMwF7gGQERC1mi8K9sw33E4rJgYWzIQQlNji/Ng60Jj3wlbCLVyNJpSrFmzj1tvXcCaNfuJirJxySXd9UZCDZgKxyhEZICIXCQiKeZ5DxH5EFhR0XXBxGU3DN1m2gqJsBg9ZCEzmL11oWEpVm9QpAlR7PYi7r77SwYOfIe9e3OZOfMSxo/XlgMaOhWtzH4GuATYADwsIguAO4DngNtqR7yq4zEIeMCaSxNCzCBg2ixIaA2tBgVbEo2mTC65ZDbffbebSZMG8NRTZ5KQEFn5RZp6T0VdTxcCvZVShSLSCNgD9FJK7aod0aqH2xyj2G/No6lpviMkWhR5h2DX9zD0Pm0pVhNS7NqVRWpqNHFxEUydeiYWizBgQMj2LmuCQEUlVpFSqhBAKXUU2B7qSgLMMQoRCiLAbSqK5NgQGA/YNBeUW29QpAkZSkpcPP30j/ToMY2nnvoBgEGDWmoloTmJiloU7UXEY0pcgHZe5yilxgdUsmristshNgZlKaKkOIqEqDAibCFgviNtNjQ9BRp3DbYkGg0//PAHt922gC1bDnPppd25+27dHaopn4oUxSWlzl8LpCD+wmW3446LBoooLIoMjfGJw+mwby2c/VSwJdFoePnlX/nrX7+hbdtEFi68irFjOwVbJE2IU5FRwG9rUxB/4cqx44wxlENeQURomBffaFqK7aktxWqCg9utyM8vIS4ugvPO60xmZgEPPzyc6OiwYIumqQPUu1FVl91OsWm90p4fHvwNi5QyZju1Gw7xzYIri6ZB8ttvhxgx4gOuv/5zADp3Tubpp0dpJaHxmYAqChE5R0S2iUi6iJS5h4WITBCRzSLym4h8XNM03dl2CqONMYmjdlvwWxQZqyHrd712QlPrFBQ4+Pvfl9Cnz5ts2ZLJuHGdUEoFWyxNHcTntfgiEqGUKq5CeCvwOjAayABWicgXSqnNXmE6AX8HTldKZYlIY99FLxuX3U5exybEhsWyv0RIiQvyjKe0WWCL1JZiNbXKunX7GT9+Nr//ns0NN/Th+edHk5ISHWyxNHWUSlsUIjJQRDYCO8zz3iLybx/iHgikK6V2KaVKgJkYazO8+QvwulIqC0ApdahK0pdCud24cnLIjXATF5YIBHkLVJcDfvvUtBSrrWxqAo+nxdC6dQKtWyewbNn1vPfehVpJaGqEL11P/wLGAUcAlFIbgDN8uK4FxiI9Dxmmmzedgc4i8rOILBeRc3yIt1zc+fngdpMV7iTaFgKrsnd+BwVH9NoJTcBxOt288spyRo36EJfLTXJyNMuWXc/w4W2CLZqmHuCLorAopf4o5ebyU/o2oBMwErgSeFtEEksHEpFbRGS1iKzOzMwsNzKP+Y6j4SWESwjYeUrzWIo9K3gyaOo9K1fuZeDAt7nvvq+JjLSRk+NzD7FG4xO+KIo9IjIQUCJiFZF7ge0+XLcXaOV13tJ08yYD+EIp5VBK7TbjPWlSt1LqLaVUf6VU/9TU1HIT9FiOzbQVYlOGomgcrBZFca5hBLDHxdpSrCYg5OWVMGnSQk477R0OHsxnzpzLWLjwKpKS9G5zGv/ii6K4Hfgr0Bo4CJxmulXGKqCTiLQTkXDgCuCLUmHmYbQmMC3UdgaqbSbEnWMoikPWfJQrBhFoFKyN3rcuBGehnu2kCRhhYRaWLv2Du+4ayJYtk7j00u6ISLDF0tRDfJn15FRKXVHViJVSThG5E/gasALvKaV+E5EngNVKqS9Mv7NFZDNGd9YUpdSRqqblwdP1lBXhJM4ZTaPocGzWIC0VSZsFidpSrMa/pKcf5YknlvH662OJi4tgzZpbiIzUGwlpAosvOWyViGwDZgGfKqVyfY1cKbUIWFTK7RGvY4XRWvmrr3FWhEdR5EVBeHFU8Aaycw/CrqUw9K+ga3gaP1Bc7OT5539m6tQfCQ+38pe/nMqwYW20ktDUCpVWt5VSHYCngH7ARhGZJyJVbmHUBp4xivxIKCiMDN5AtsdSrN4XW+MHvv9+N717T+eRR5Zy0UVd2br1ToYN07OZNLWHT/0ySqlflFJ3A6cCOcB/AypVNXHl5KAiwnDYhNyCiOC1KDbOhma9IbVLcNLX1BuUUkyd+iMOh5uvvprIzJmX0rx5XLDF0jQwKm23ikgsxkK5K4BuwOfAkADLVS1c9mycsVFAAVm54aQEYx+Kwztg3zo4e2rtp62pF7jdinffXcs553SkVasEZsy4mMTESKKitG0mTXDwpUWxCWOm0/NKqY5KqclKqZDcM9tlt+MwLccWB2uMIm02iAV6lrbSrtFUTlraQYYOfY9bblnAO++sBaBZszitJDRBxZeRsPZKKXfAJfED7mw7RTE2bGIDdxC6npQyup20pVhNFcnLK+Hxx5fy8svLSUqK4oMPLuTaa3sHWyyNBqhAUYjIP5VSk4G5InKSyclQ3OHOlZNDQYyFmLAEspDaH8zOWGVYih1xf+2mq6nzPPbYUv75z1+5+ea+PPvsWSQna9tMmtChohbFLPO/TuxsB0bXU26ylShLAhAEO08eS7Fdx9Vuupo6yZ49dvLzHXTtmsIDDwzloou6MnRo62CLpdGcRLljFEqpleZhN6XUt94/jEHtkMNlt2OPcBEusUAt23lyOWDTp9BlrLYUq6kQp9PNSy/9Srdur3PrrQsASEmJ1kpCE7L4Mph9YxluN/lbkJriLi5GFRWRFeHAomKxWoSk6Fqc9ZT+LRQe1WsnNBWyfHkG/fu/xeTJ3zByZFv+85+Lgi2SRlMpFY1RXI4xJbadiHzq5RUHZAdasKriWZV92FaEcsaQHBOO1VKLq6I3zoaoRtBhVO2lqalTLFy4nfPP/x/Nm8fx6acTuOiirto2k6ZOUNEYxUqMPShaYuxU5yEXWBdIoaqD26MowopwOKJrt9upOBe2LoI+V2lLsZoTUEqxb18uLVrEc9ZZ7XniiTO4555BxAV7L3eNpgqUqyhMs9+7gSW1J071OWbnKRKKiyNpU5sf4pYF2lKs5iS2bz/CHXcsZPv2I2zePInY2HAefnh4sMXSaKpMRV1Py5RSI0QkC/CeHisY9vwaBVy6KnDcIKCQVxBJSotaVBRpsyCxDbQaWHtpakKWoiInzz77E8888xNRUTaeeWYUUVHaeJ+m7lJR7vVsd5pSG4LUFJc9BzBaFLm54bU3NTb3AOxeBsMma0uxGg4cyGP48PfZseMoV17Zk5deGkPTprHBFkujqREVTY/1rMZuBViVUi5gMHArEFMLslUJ764nhyOm9hSFx1Ks3he7QeNwGLsDN2kSw/Dhbfjmm6v5+ONLtJLQ1At8mR47D2Mb1A7A+xhblX4cUKmqgcuejbIIhRGgXNG1ZxAwbTY06wOpnWsnPU1I4XYrpk9fTYcO/yIjIwcR4Z13LmD06A7BFk2j8Ru+KAq3UsoBjAf+rZS6D2gRWLGqjmEQMBJEUM5aalFkbof96/XaiQbKhg0HGDLkXW6/fSGdOiUfa1VoNPUNn7ZCFZHLgGsAz+qgkDNl6bbnUBJtI9ISTi5WUmtjeuxGbSm2IaKUYsqUxbzyynIaNYpixoyLmTixl14Toam3+KIobgTuwDAzvktE2gH/C6xYVcdlt1MQbSXSamzqEvAWhVJGt1O7ERDXNLBpaUIKESErq5CbbjIM+CUlRQVbJI0moPiyFeom4G5gtYh0BfYopUJuVx6X3U5+lGBTsYRZhYRA2+/fsxKy/9BrJxoIf/yRzUUXzWTt2v0AvP32Bbz55vlaSWgaBJUqChEZBqQD7wLvAdtF5PRAC1ZVXHY7ORFuRMWSEhsR+G6AtFlgi4Ju2lJsfcbhcPH88z/Tvfs0Fi/exbZthwGw1KZ5GI0myPjS9fQyMFYptRlARLoBM4D+gRSsqrjsdrKbu3A7ogPf7eQsgd8+g65jIULvX1xf+eWXPdx66wI2bTrEhRd24V//OpfWrROCLZZGU+v4oijCPUoCQCm1RURCyqCRcrlw5+ZyJMxKSUkt2Hna6bEUq7ud6jNLluzCbi9i3rzLufDCrsEWR6MJGr4oirUiMh34yDyfSIgZBXTn5oJS2CPdFBZFkpocYEWRNhuik6HDmYFNR1OrKKWYMSON1NRozj23E/fffzp//etgYmtrTY5GE6L4so7iNmAX8H/mbxfG6uyQwXtVdn5hZGC7nopyYNsi6DEerCE3S1hTTbZuPcyZZ37IddfN4/331wMQEWHTSkKjoZIWhYj0AjoAnymlnq8dkaqOR1HkR4LLGeBV2VsXgLNIL7KrJxQWOnj66R957rmfiYkJ5803x3HzzacGWyyNJqQot0UhIg9imO+YCCwWkbJ2ugsJjhkEjPKsyo4MXGJpsyCpLbQcELg0NLXG/PnbeeqpH7n88p5s3TqJW27pp2c0aTSlqKhFMRE4RSmVLyKpwCKM6bEhx3ET46CKYgLXosjZD7uWwfAp2lJsHebAgTzWrz/AOed05LLLutO27c0MHBhyVmk0mpChojGKYqVUPoBSKrOSsEHFZTd2Zs2LBOUKoJ2nTXMBpbud6igul5tp01bRpctrXHPNZxQWOhARrSQ0mkqoqEXR3muvbAE6eO+drZQaH1DJqoCnRVEYaQN3BCmBUhRps6B5X0jpFJj4NQFj7dr93HbbAlat2sdZZ7Vn2rSxRAV69b5GU0+oSFGUtnT3WiAFqQluew6OCBu2sHgibFbiIgKwm9ihrXAgDc551v9xawLK7t1ZDBz4Nikp0Xz88XiuuKKnNuCn0VSBivbM/rY2BakJLrudohgbVhVLalyAzHd4LMX2CJmGlKYClFJs3HiIU05pQrt2Sbz//oWcf34XEhMDONFBo6mnhOy4Q1XwGATEFROYVdluN2ycA+3PgLgm/o9f41d2785i3Lj/0bfvm6SlHQTgmmt6ayWh0VSTgCoKETlHRLaJSLqIPFBBuEtERIlItexHuex28iIUrkBtWLRnBWT/qQexQ5ySEhfPPvsTPXpMY9my33nxxdF0754abLE0mjqPz535IhKhlCquQngr8DowGsgAVonIF952o8xwccA9wApf4y6NK8dOdoSL4uJIUgJhvmPjbAiLhq7aUmyo4nK5GTLkXdas2c/48d145ZUxtGqlDfhpNP7AFzPjA0VkI7DDPO8tIv/2Ie6BQLpSapdSqgSYCVxYRrgngeeAIt/FPhFXtp3sCCeFRVH+b1F4LMV2GQsRsf6NW1NjcnKMuovVauHGG/syf/6VzJ07QSsJjcaP+NL19C9gHHAEQCm1ATjDh+taAHu8zjMotde2iJwKtFJKLawoIhG5RURWi8jqzMzME/yUUkbXU6DWUKQvgcIsbSk2xFBK8cEH62nf/lU+/3wrAHfcMYBx4zoHWTKNpv7hi6KwKKX+KOVW413kRcQCvARMriysUuotpVR/pVT/1NQT+5xVYSE4HORHmuY7/L0qO22WaSnWF92oqQ02b85k5Mj/cMMNn9O1awodOjQKtkgaTb3GlzGKPSIyEFDmuMNdwHYfrtsLtPI6b2m6eYgDegJLzemsTYEvROQCpdRqX4QHcOV47DyBcvl506IiO2z/Ck69VluKDRGef/5nHnroO+LjI3jnnfO54Ya+2jaTRhNgfFEUt2N0P7UGDgJLTLfKWAV0EpF2GAriCuAqj6dSyg6keM5FZCnwt6ooCTjRxLhyxfp3euyW+Yal2F56tlOwUUohIjRtGsvEib144YXRpKbGBFssjaZBUKmiUEodwijkq4RSyikidwJfA1bgPaXUbyLyBLBaKfVFlaUtA1e2l0FAf+9ulzYbktpBy5Da9bVBsW9fLvfc8xXDhrXm7rsHce21vbn22t7BFkujaVBUqihE5G1AlXZXSt1S2bVKqUUYVme93R4pJ+zIyuIri+MGAYVoZzwx/jLfkbMPdv8AI/5PW4oNAh4Dfg899B0Oh5shQ1oGWySNpsHiS6m6xOs4EriYE2czBRW3OUZRFBlFikT7L2KPpVjd7VTrrF9/gJtv/oI1a/Zz9tkdmDZtrB6w1miCiC9dT7O8z0VkBvBTwCSqIp4xioKIWJqH+bPbaRY0PxVSOvovTo1P2O1F7NuXy6xZl3LZZd21AT+NJshUp5+mHRAyBo9c2XZcVqHIEkNKtJ8UxaEtcGAjnPOcf+LTVIhSijlzNrNjxxEeemg4I0a0Zdeue4iMDIAVYI1GU2V8WZmdJSJHzV82sBj4e+BF8w2X3U5hlAWHP+08pc0GsUJPbSk20OzceZSxYz/m8ss/4fPPt+FwGEt0tJLQaEKHCr9GMdr8vTm+/sGtlDppYDuYuHJyyIsUHCV+Mt/hdsPGT4wFdrGNax6fpkyKi528+OIvPPXUj4SFWXj11XO4444B2Gz1wqCxRlOvqFBRKKWUiCxSSvWsLYGqiis7m5xIN26nn9ZQ7FkO9j/hzIdrHpemXPbsyeHJJ3/g/PO78MorY2jRIj7YImk0mnLwpfq2XkT6BlySauKwZ5Ebqfy3KjvNYyn2vJrHpTmBzMx8XnttJQAdOzZi8+ZJzJlzmVYSGk2IU26LQkRsSikn0BfDRPhOIB9j/2yllDq1lmSsEGd2NnnJhkHAlJraefJYiu16nrYU60fcbsX776/j//5vCbm5xYwe3Z4uXVJo3z4p2KJpNBofqKjraSVwKnBBLclSLdw5OeS18JPl2PTFUJStLcX6kU2bDnH77Qv56ac/GTasNdOnj6NLl5TKL9RoNCFDRYpCAJRSO2tJliqjHA4kv5C8KAvK6YdtUNNmQXSKseWppsaUlLg4++wZlJS4eO+9C7j++j56TYSmXBwOBxkZGRQVVXtrGg0QGRlJy5YtCQvznyHTihRFqoj8tTxPpdRLfpOimrhycwHDIGCMLZ7IMGv1Iyuyw7avoN/1YNVTM2vCd9/tZsSINoSHW5k9+zK6dk0hJcWPq+Y19ZKMjAzi4uJo27atrlBUE6UUR44cISMjg3bt2vkt3ooGs61ALIY58LJ+QcdjEDA/EpKja2jiYfMX4CrW+2LXgIyMHC65ZDajRn3Ihx9uAGDo0NZaSWh8oqioiOTkZK0kaoCIkJyc7PdWWUVV5/1KqSf8mpqfced4TIxbSI2p4daXG2dDo/bQop8fJGtYOJ1uXnttJf/4x/e4XG6eeWYUEyeeEmyxNHUQrSRqTiCeYaVjFKHMcTtP0TSNi6x+RDn7YPePMOJ+bSm2GlxzzWfMnLmJc8/tyOuvj6VdOz2bSaOpT1TU9TSq1qSoJh5FkRMWTWpNBrI3fgIo3e1UBbKzi8jLKwFg0qQBzJlzGQsXXqWVhKbe8Nhjj/Hiiy9WGGbevHls3rzZr+n+/vvvfPzxx+X6n3POOSQmJjJu3Di/plsR5SoKpdTRWpOimnjGKLJtcTWbGps22+hySu7gJ8nqL0opZs7cRLdur/OPf3wHGOMQl16qrbxqGh7BUBRTpkxhxowZfk2zMur09B7Pftn51tjqtygOboaDG+Hc5/0oWf0kPf0od9yxkMWLd9G/f3OuvlqPQ2gCw+Pzf2Pzvhy/xtm9eTyPnt+jwjBTp07lP//5D40bN6ZVq1b062eMWb799tu89dZblJSU0LFjR2bMmMH69ev54osvWLZsGU899RRz587lu+++OylcdHQ0c+bM4fHHH8dqtZKQkMAPP/yAy+XigQceYOnSpRQXFzNp0iRuvfVWHnjgAbZs2UKfPn247rrruO+++06QcdSoUSxdutSvz6Yy6rQFNpfdTkEEuFQsKXHVXJW90bQU20Nbiq2Ijz/eSM+e01ixYi+vvXYuy5ffRL9+zYMtlkbjN9asWcPMmTNZv349ixYtYtWqVcf8xo8fz6pVq9iwYQPdunXj3XffZciQIVxwwQW88MILrF+/ng4dOpQZDuCJJ57g66+/ZsOGDXzxhbEL9LvvvktCQgKrVq1i1apVvP322+zevZtnn32WYcOGsX79+pOURLCo0y0KZ3YWuVHmquzYagxmH7MUeybEpvpfwHqAw+EiLMxK//7NufTS7jz//GiaNw+J2dGaekxlNf9A8OOPP3LxxRcTHW1M577gguNGKTZt2sTDDz9MdnY2eXl5jBkzpsw4ygt3+umnc/311zNhwhyG3FkAABl/SURBVATGjzcqpd988w1paWl88sknANjtdnbs2EF4eA1NEQWAOq0oirMOkxdZA/Mdf/4K9j0wqsxtvBs0hw7lM3nyN+Tnl/Dpp5fTuXMyH32kW12ahsn111/PvHnz6N27Nx988EG5XT/lhZs+fTorVqxg4cKF9OvXjzVr1qCU4t///vdJSqe2u5V8oU53PZVkZ5MfKShnDMnVMQi4cTaExWhLsV643Yq33lpDly6vMWvWJnr0SMXlcgdbLI0m4AwfPpx58+ZRWFhIbm4u8+fPP+aXm5tLs2bNcDgc/Pe//z3mHhcXR65pIaKicDt37mTQoEE88cQTpKamsmfPHsaMGcMbb7yBw+EAYPv27eTn558UZyhQp1sULrudvFiIsSUQZq2iznMWH7cUGx4TGAHrGLt2ZXH11Z/y668ZjBzZljfeOI+uXbUBP03D4NRTT+Xyyy+nd+/eNG7cmAEDBhzze/LJJxk0aND/t3fv4VGV597HvzeBJEA4aEiUGCqeOISQQIhyqlIELSDFw8YSFWi2gqKlasVs2PXUg93Kxpb9oqSBt7ZoX6oc+nLYFEVtQZAGNGxjAKEgchQUGgkhARKS3PuPtUICzWGCM5lZyf25Li5n1qxZ68ljMvesZ631e4iJiaF///7nPsjT0tKYPHkyc+bMYenSpbWul5GRwe7du1FVhg0bRnJyMklJSezbt4+UlBRUlZiYGJYvX05SUhJhYWEkJyeTnp7+T+cpbrzxRnbu3ElRURHx8fG8+uqrtQ6F+YuE2IR19UpNTdWcnBwAtvW/nr9cXcyyAU+z7rF7G7ahHatg0X1w35/guuEBaKn35Oef4sYbf8+MGd9mwoQku9zVNKodO3bQs2fPYDejSaipL0Vki6qmXsz2PDv0pKq0OFlMUWuIaRPd8A3kLYK2MXD1d/zdNE9ZufLv3HXXIsrLK4iObsO2bY8wcWKyFQljzDmeLRQVxaeQCqU4Urg8qoGBgKcLYNcaSPyXZpsUe+DACe64401uv/1Ndu3K58iRIgBatLACYYw5n2c/JStOFABwMjyc2HYNPMeww02K7d38IjvKyir4r//axHPPrUNVmTlzOD/+8QBafZOIdmNMk+bZQlGZ83QyPIJeDb00Nm8xXHoNXBESs7k2qvLyCn772//h5puv4uWXR9K1a8dgN8kYE+I8O/RUWSiKwts0bGa7E1/Avg+c6U6byTj88eOnmT79XU6eLCEioiUbN97PypVpViSMMT7xcKFwcmBOtoxq2M1229yk2N5jA9OwEKKqLFyYR48ec/nVr7JZu3YfANHRbexktTHGZx4uFJUR4+0aFgiYtxjir2/ySbG7duVzyy1/YPz4ZXTt2pGcnAcZM6Z7sJtljGeEYsx4bm4uAwcOpFevXiQlJbFo0SK/7rs2Hi4U7snslu19DwT8ajt8ta1ZnMR+/PG3yck5TGbmKP72t/vp0+fyYDfJmCansQtFmzZteP3119m+fTtvv/02jz/+OAUFBX7df008ezL7zNf/oLQllLZoT3RbH48o8tyk2MSmmVn07rt76NGjE126dOA3v7mNiIiWXH55VLCbZUzDvTUDvtzq321e3htGvljnKqEeM96tW7dzj+Pi4oiNjeXYsWN07BjY840BPaIQkREi8ncR+UxEZtTw+hMi8qmI5InIX0TkSl+3fdoNBGwb1p4wX679r0yKvXYYtG1asRRfflnEvff+iVtv/X/MnLkRgCuv7GhFwpgG8FrM+IcffkhpaSnXXBP4YfSAHVGISBgwF7gFOAR8JCIrVbX6cdrHQKqqnhKRh4H/BMb5sv3SgnyKIqFDuI9Tbx74GxQeglt+1pAfI6RVBvjNmPEep0+X8dxzQ5gx49vBbpYx31w93/wDwUsx40eOHGHChAm89tprtGgR+DMIgRx6ugH4TFU/BxCRN4HbgXOFQlXXVlt/EzDe142XFRRQ1Boube1jochb5CTFdh/p6y5C3gsvbODpp9dy881XkZk5iu7dm9aRkjGhIpRixgsLC7ntttv45S9/yYABA/zw09UvkKXoCuBgteeH3GW1eQB4q6YXRORBEckRkZxjx44BUHGikOJIIdaXnKezZ2D7Cuj5Pc8nxZ48WcLevccBmDIllYUL7+K99yZYkTDmG/JCzHhpaSl33nknEydOZOzYxrvEPySuehKR8UAqMKum11V1vqqmqmpqTIwzE50UFVMUCXHtfCgUu9+BkhOQdLcfW924VJVly3aQkJDJuHFLUVWio9tw77297Z4IY/ygesz4yJEja4wZHzx4MD169Di3PC0tjVmzZtG3b1/27NlT63oZGRn07t2bxMREBg0aRHJyMpMmTSIhIYGUlBQSExN56KGHKCsrOy9mfPbs2ee1cfHixaxfv54FCxbQp08f+vTpQ25ubsD7JmAx4yIyEPipqn7Xff7vAKr6wgXrDQdeBoao6tH6tlsZM741uTdvJSkdJ63gwSH1nMxZNB4ObIYndngyBHD//gKmTn2LVat2kZR0GfPmjWbAgPhgN8sYv7KYcf/xd8x4ID81PwKuE5GrgC+ANOC8SSNEpC8wDxjhS5GoVFFaSsuSMk5GtKZb+3rmyj593EmKTX3Ak0UiO/sgw4f/AYCXXrqFxx4bQMuWIXEgaIxpJgL2yamqZSIyFVgDhAG/U9XtIvJzIEdVV+IMNUUBS9zhkwOqOqbWjboqzuU8Rdaf8/TpSigvhSRv3WRXWFhC+/YRpKR05v77+5CRMZhvfatDsJtljGmGAvoVW1VXA6svWPZstccXNbVceaGb8xTeuv6cp7zFEH0txPW9mF01uvz8U8yY8R7vvPM527c/QlRUOC+/PCrYzTLGNGOeHMM4FzHesm3dhaLgIOz3RlKsqvL665/Qo8dcfv/7XMaN6xXqTTbGNBPeG7QHygsqh56i6Ni6Ve0rbnNuZAn1pNgTJ85wxx2LWLduHwMHxpOVNZqkpMuC3SxjjAE8WihKC/IBKGvTse6pO/OWQPwNcOnVjdSyhlFVRIT27SPo1KkN8+eP5oEHUmw6UmNMSPHk0FPx184FUhJVxz0UX26Do9tD9iT2mjWfkZIyn0OHChERliy5m8mT+1mRMCZEhGLM+P79+0lJSaFPnz706tWLrKwsv+67Np4sFKfyv6ICiGxfx/DM1sXQoiX0urPR2uWLI0dOkpa2lBEjFnLq1FmOHi0OdpOMMRepsQtF586dyc7OJjc3l82bN/Piiy9y+PBhv+6/Jp4ceio5nk9JJFxaW3xHZVLsNaGVFDt37of85Cd/paSkjJ/97DtMnz6YiAhP/i8wJqBmfjiTnV/v9Os2e1zag+k3TK9znVCPGa8eGFhSUkJFRYVf+6g2njyiKD1+nKLWcFltQ0/7N0LhFyE37LRlyxH697+CrVsf5tlnh1iRMCaEeCVm/ODBgyQlJdGlSxemT59OXFxcwPvGk59UZ08UUBwJcVG1HC3kLYLwKOge3PsPCgtLePbZtUyYkES/fnFkZt5GRESYZTMZU4/6vvkHgldixrt06UJeXh6HDx/mjjvuYOzYsVx2WWCvkvTkEYWeKKIoUojvWEOhOHvGuRu75/cgvE3jNw7naqalSz+lZ8+5zJmzmfff3w9AZGRLKxLGeFB6ejqvvPIKW7du5bnnnuPMmTMNWi8rK4vnn3+egwcP0q9fP/Lz88/FjOfm5pKbm8vevXu59dZbfW5TXFwciYmJbNiwwS8/Y108WShaFJ2iKDKMy9vVEBm+e42TFNs7OEmxe/ceZ/ToN7j77iXExrYlO/sBnnhiYFDaYozxnRdixg8dOsTp06cBOH78OB988AHdu3f3az/UxJNDT+HFZzgZF17zXdl5iyHqMrhqSOM3DFi4cCvr1+9n9uzvMnXqDRbgZ4xHVI8Zj42NrTFmPCYmhv79+5/7IE9LS2Py5MnMmTOHpUuX1rpeRkYGu3fvRlUZNmwYycnJJCUlsW/fPlJSUlBVYmJiWL58+Xkx4+np6eedp9ixYwfTpk1DRFBVnnzySXr37h3wvglYzHigpKam6mvFxfzp+o48lrWeDm2q3Zl9+ji81A2unwQjXqh9I362YcN+SkrKGT78akpKyjh27BTx8e0bbf/GNAUWM+4//o4Z997X3fJyWigUhbemfesLDog+XdGoSbH/+Mcp7r9/BTfdtICf//x9ACIiWlqRMMY0KZ4betLycgBKWkf984nhvMUQfR107hPYNqiyYEEuGRnvcuJECdOnD+aZZ24K6D6NMSZYPFsozra54Ft7wUHn/omhTwc8KXb16t3cf/9KBg/uQlbWaBITYwO6P2OMCSbPFYqKsrMgYUi7S85/YesS578BSoo9deosH398hMGDv8WoUdexYkUao0d3s2wmY0yT57lzFOVlzqVkrdrHVC1UdYaduvSHS6/y+z7fems3iYmZjBy5kIKCM4gIY8Z0tyJhjGkWPFcoKtxC0Tr68qqFX22DYzv8fu/EF18UcvfdSxg16o9ERLTkv//7Hjp2rGeObmOMaWI8VyjKy8oAuKRTfNXCvMqk2Lv8tp+jR4tJSMhk1apdPP/8UD75ZApDhnT12/aNMaEtFGPGKxUWFhIfH8/UqVP9uu/aeK5QVJSVcaYVdK48oqgod5Jirx0ObeuYn8JHX3zhzMcdG9uWX/xiKNu2PcxTT91EeHjYN962MaZpCVaheOaZZ7jppsa70tJzJ7O1vJyiSLiyo3ul0f6NcPIwfPf5b7TdEyfO8PTTf2XevC1s2jSJlJTOPPpofz+02BjTUF/+x39QssO/MeMRPXtw+U9+Uuc6oR4zDk7K7VdffcWIESPIycnxax/VxnNHFJSXO4GAHTo6zyuTYruNvKjNqSqLF2+nZ8+5zJ37EVOmpHLNNZfU/0ZjTJPihZjxiooKpk2bVu+QmL957oiCigqKIsOIbR9ZLSl2zEUlxaoqd921mOXLd5KS0pmVK+8hNTXw2e7GmLrV980/ELwQM56ZmcmoUaOIj4+vdZ1A8FyhaFFRQXFEK9qGh8Gnq6CkEJIadrXT2bPltGrlzAvx7W934eabu/LII9cTFua9AyxjTOClp6ezfPlykpOTWbBgAevWrWvQellZWWzevJk///nP9OvXjy1btpyLGb+w6NS2bYDs7Gw2bNhAZmYmRUVFlJaWEhUVxYsvvuinn7RmnvtklArlVGSEE9+xdUmDk2LXrdtHUlIWK1Y445/Tpg3iRz/qb0XCmGbOCzHjCxcu5MCBA+zbt4+XXnqJiRMnBrxIgAcLRVgFnGndGk59DbvWQOJYaFH/FUnHjhXzgx8sZ+jQ1ygpKaNdTRHlxphmq3rM+MiRI2uMGR88eDA9evQ4tzwtLY1Zs2bRt29f9uzZU+t6GRkZ9O7dm8TERAYNGkRycjKTJk0iISGBlJQUEhMTeeihhygrKzsvZnz27NmN2ge18VzMeGJka52QfivTJ90Bqx6HB9+HuLpDAN94Yys//OFqiopKycgYxFNP3USb6vHkxpigs5hx//F3zLjnzlEAaFR75ya7Tt2gc3K965eVVZCYGEtW1mgSEmLqXd8YY0wVzw09AUS2jYQDf3PmnaghKba4uJQZM94jM9O5vG38+CTefz/dioQxxlwETxaKzmFfOw9qyHZatWoXvXplMnPmRnbtygdARP557gpjTMjx2lB4KApEH3py6KnL2c+g6wC4pOu5ZYcOFfLoo2+xbNlOEhJiWL8+nRtvvDJ4jTTGNEhkZCT5+flER0fbF7uLpKrk5+cTGenf8FJPFopOZUcg6UfnLfv88+OsWbOHF14YxhNPDLRsJmM8Jj4+nkOHDnHs2LFgN8XTIiMj/X5Dnievevrrv7UjdsZOPtx2muzsgzz22AAA8vNPER3d8Du0jTGmqfsmVz0F9ByFiIwQkb+LyGciMqOG1yNEZJH7+mYR6VrfNlWgPG4ojzyZzYABv+XXv95EcXEpgBUJY4wJgIAVChEJA+YCI4EE4B4RSbhgtQeA46p6LTAbmFnfdgsqwun7dBLz5m3h0Uf7s3Xrw7RtW3s2ijHGmG8mkOcobgA+U9XPAUTkTeB2oHp4++3AT93HS4FXRES0jvGwI6Vt6de1E6vfGUNKSufAtNwYY8w5gSwUVwAHqz0/BFw4wcO5dVS1TEROANHAP6qvJCIPAg+6T0tytkzZ1q/flIA02mM6cUFfNWPWF1WsL6pYX1TpfrFv9MRVT6o6H5gPICI5F3tCpqmxvqhifVHF+qKK9UUVEbnoWY4CeTL7C6BLtefx7rIa1xGRlkAHID+AbTLGGNNAgSwUHwHXichVIhIOpAErL1hnJfAD9/FY4K91nZ8wxhjT+AI29OSec5gKrAHCgN+p6nYR+TmQo6orgVeBP4jIZ8DXOMWkPvMD1WYPsr6oYn1RxfqiivVFlYvuC8/dcGeMMaZxeTIU0BhjTOOxQmGMMaZOIVsoAhH/4VU+9MUTIvKpiOSJyF9EpMnG5tbXF9XW+xcRURFpspdG+tIXIvJ993dju4j8sbHb2Fh8+Bv5loisFZGP3b+TUcFoZ6CJyO9E5KiIbKvldRGROW4/5YlIik8bVtWQ+4dz8nsPcDUQDnwCJFywziNAlvs4DVgU7HYHsS+GAm3cxw83575w12sHrAc2AanBbncQfy+uAz4GLnGfxwa73UHsi/nAw+7jBGBfsNsdoL64CUgBttXy+ijgLUCAAcBmX7YbqkcU5+I/VLUUqIz/qO524DX38VJgmDTNEPt6+0JV16rqKffpJpx7VpoiX34vAH6Bkxt2pjEb18h86YvJwFxVPQ6gqkcbuY2NxZe+UKC9+7gDcLgR29doVHU9zhWktbkdeF0dm4COIlJvFlKoFoqa4j+uqG0dVS0DKuM/mhpf+qK6B3C+MTRF9faFeyjdRVX/3JgNCwJffi+6Ad1EZKOIbBKREY3WusblS1/8FBgvIoeA1cCPaJ4a+nkCeCTCw/hGRMYDqcCQYLclGESkBfBrID3ITQkVLXGGn76Dc5S5XkR6q2pBUFsVHPcAC1T1VyIyEOf+rURVrQh2w7wgVI8oLP6jii99gYgMB54CxqhqSSO1rbHV1xftgERgnYjswxmDXdlET2j78ntxCFipqmdVdS+wC6dwNDW+9MUDwGIAVc0GInECA5sbnz5PLhSqhcLiP6rU2xci0heYh1Mkmuo4NNTTF6p6QlU7qWpXVe2Kc75mjKpedBhaCPPlb2Q5ztEEItIJZyjq88ZsZCPxpS8OAMMARKQnTqFojnOurgQmulc/DQBOqOqR+t4UkkNPGrj4D8/xsS9mAVHAEvd8/gFVHRO0RgeIj33RLPjYF2uAW0XkU6AcyFDVJnfU7WNfTAP+r4j8GOfEdnpT/GIpIm/gfDno5J6PeQ5oBaCqWTjnZ0YBnwGngH/1abtNsK+MMcb4UagOPRljjAkRViiMMcbUyQqFMcaYOlmhMMYYUycrFMYYY+pkhcKEHBEpF5Hcav+61rFu19qSMhu4z3Vu+ugnbuRF94vYxhQRmeg+TheRuGqv/VZEEvzczo9EpI8P73lcRNp8032b5ssKhQlFp1W1T7V/+xppv/epajJO2OSshr5ZVbNU9XX3aToQV+21Sar6qV9aWdXOTHxr5+OAFQpz0axQGE9wjxw2iMj/uP8G1bBOLxH50D0KyROR69zl46stnyciYfXsbj1wrfveYe4cBlvdrP8Id/mLUjUHyEvusp+KyJMiMhYnc2uhu8/W7pFAqnvUce7D3T3yeOUi25lNtUA3EfmNiOSIM/fEz9xlj+IUrLUistZddquIZLv9uEREourZj2nmrFCYUNS62rDTMnfZUeAWVU0BxgFzanjfFOD/qGofnA/qQ25cwzhgsLu8HLivnv1/D9gqIpHAAmCcqvbGSTJ4WESigTuBXqqaBDxf/c2quhTIwfnm30dVT1d7+U/ueyuNA968yHaOwInpqPSUqqYCScAQEUlS1Tk4kdpDVXWoG+XxNDDc7csc4Il69mOauZCM8DDN3mn3w7K6VsAr7ph8OU5u0YWygadEJB74/6q6W0SGAf2Aj9x4k9Y4RacmC0XkNLAPJ4a6O7BXVXe5r78G/BB4BWeui1dFZBWwytcfTFWPicjnbs7ObqAHsNHdbkPaGY4T21K9n74vIg/i/F13xpmgJ++C9w5wl2909xOO02/G1MoKhfGKHwNfAck4R8L/NCmRqv5RRDYDtwGrReQhnJm8XlPVf/dhH/dVDxAUkUtrWsnNFroBJ2RuLDAVuLkBP8ubwPeBncAyVVVxPrV9biewBef8xMvAXSJyFfAkcL2qHheRBTjBdxcS4F1VvacB7TXNnA09Ga/oABxx5w+YgBP+dh4RuRr43B1uWYEzBPMXYKyIxLrrXCq+zyn+d6CriFzrPp8AvO+O6XdQ1dU4BSy5hveexIk9r8kynJnG7sEpGjS0nW6g3TPAABHpgTN7WzFwQkQuA0bW0pZNwODKn0lE2opITUdnxpxjhcJ4RSbwAxH5BGe4priGdb4PbBORXJx5KV53rzR6GnhHRPKAd3GGZeqlqmdw0jWXiMhWoALIwvnQXeVu7wNqHuNfAGRVnsy+YLvHgR3Alar6obuswe10z338CicV9hOc+bF3An/EGc6qNB94W0TWquoxnCuy3nD3k43Tn8bUytJjjTHG1MmOKIwxxtTJCoUxxpg6WaEwxhhTJysUxhhj6mSFwhhjTJ2sUBhjjKmTFQpjjDF1+l9tr5kVx/ajVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves for Naive Bayes\n",
    "plot_roc(fpr_bayes, tpr_bayes, 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves for Logistic Regression\n",
    "plot_roc(fpr_lgr, tpr_lgr, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ROC, AUC and accuracy, we can see that:\n",
    "1. Each preprocessed dataset doesn't have much impact on performance for both Naive Bayes and Logistic Regression models; the four datasets lead to similar ROC, AUC and accuracy for both models.\n",
    "2. Particularly, dataset 3 using $\\log (x_{ij}+0.1)$ yields the best ROC, AUC and accuracy for both models; therefore, $\\log (x_{ij}+0.1)$ is the best preprocessing method among the four methods for both models.\n",
    "3. Logistic Regression model outperforms Naive Bayes model for each preprocessing method; therefore, Logistic Regression is preferred over Naive Bayes for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploring Model Selection Strategies for Logistic Regression with Regularization\n",
    "#### We will be using the SPAM dataset from the previous part for this problem. You can preprocess the data however you see fit, either based on the results of the previous problem or introducing another preprocessing method. The only requirement is that it is consistent throughout the rest of this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Implement the validation/hold-out technique for logistic regression (regularized model), where the performance is reported for the validation portion. Your implementation should work for any user-specified split ratio (this will help with the later parts of this problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define method of hold-out validation\n",
    "import math\n",
    "\n",
    "def cv_holdout(lgr, lambdas, X, y, ratio_holdout):\n",
    "    # Get training and validation set\n",
    "    idx_shuffle = np.arange(y.shape[0])\n",
    "    np.random.shuffle(idx_shuffle)\n",
    "    cnt_holdout = math.floor(y.shape[0] * ratio_holdout)\n",
    "    X_train = X[idx_shuffle[cnt_holdout:]]\n",
    "    y_train = y[idx_shuffle[cnt_holdout:]]\n",
    "    X_valid = X[idx_shuffle[:cnt_holdout]]\n",
    "    y_valid = y[idx_shuffle[:cnt_holdout]]\n",
    "    \n",
    "    # Search parameter lambda\n",
    "    lambda_best = None\n",
    "    accuracy_best = 0\n",
    "    for lambda_ in lambdas:\n",
    "        lgr.set_params(C=1/lambda_, warm_start=False)\n",
    "        lgr.fit(X_train, y_train)\n",
    "        \n",
    "        accuracy = lgr.score(X_valid, y_valid)\n",
    "        if accuracy > accuracy_best:\n",
    "            accuracy_best = accuracy\n",
    "            lambda_best = lambda_\n",
    "    \n",
    "    return lambda_best, accuracy_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Implement the k-fold cross-validation approach for logistic regression (regularized model), where the performance is reported from the k-different validation. Your implementation should work for any user-specified k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define method of k-fold cross-validation\n",
    "def cv_kfold(lgr, lambdas, X, y, K):\n",
    "    lambda_best = None\n",
    "    accuracy_best = 0\n",
    "    \n",
    "    cnt_fold = math.ceil(y.shape[0] / K)\n",
    "    idx_shuffle = np.arange(y.shape[0])\n",
    "    np.random.shuffle(idx_shuffle)\n",
    "    \n",
    "    for lambda_ in lambdas:\n",
    "        accuracies = []\n",
    "        idx_pre = 0\n",
    "        for i in range(K):\n",
    "            idx_valid = idx_shuffle[idx_pre : idx_pre+cnt_fold]\n",
    "            idx_train = np.hstack((idx_shuffle[:idx_pre], idx_shuffle[idx_pre+cnt_fold:]))\n",
    "            idx_pre += cnt_fold\n",
    "            X_train = X[idx_train]\n",
    "            y_train = y[idx_train]\n",
    "            X_valid = X[idx_valid]\n",
    "            y_valid = y[idx_valid]\n",
    "            \n",
    "            lgr.set_params(C=1/lambda_, warm_start=False)\n",
    "            lgr.fit(X_train, y_train)\n",
    "            accuracies.append(lgr.score(X_valid, y_valid))\n",
    "            \n",
    "        accuracy_mean = np.array(accuracies).mean()\n",
    "        if accuracy_mean > accuracy_best:\n",
    "            accuracy_best = accuracy_mean\n",
    "            lambda_best = lambda_\n",
    "    \n",
    "    return lambda_best, accuracy_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Fit ridge and LASSO using the validation/hold-out technique by searching over a variety of split ratios and regularization parameters. For each unique split ratio, specify the best ‘parameter’, report the validation error, and the test error generated from training on all the training data using the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to search best parameter by holdout validation\n",
    "import pandas as pd\n",
    "\n",
    "def search_param_by_holdout(lgr, lambdas, ratios, X_train, y_train, X_test, y_test):\n",
    "    result = []\n",
    "    for ratio in ratios:\n",
    "        lambda_, accuracy_valid = cv_holdout(lgr, lambdas, X_train, y_train, ratio)\n",
    "        lgr.set_params(C=1/lambda_, warm_start=False)\n",
    "        lgr.fit(X_train, y_train)\n",
    "        accuracy_test = lgr.score(X_test, y_test)\n",
    "        result.append([lambda_, 1-accuracy_valid, 1-accuracy_test])\n",
    "        \n",
    "    return pd.DataFrame(result, ratios, ['lambda', 'Validation Error', 'Test Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.063086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.063086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>15.556761</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>6.892612</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.063086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>17.475284</td>\n",
       "      <td>0.055333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>10.974988</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>3.853529</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>5.462277</td>\n",
       "      <td>0.065833</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>3.053856</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lambda  Validation Error  Test Error\n",
       "0.1   0.001000          0.056667    0.063086\n",
       "0.2   0.001000          0.045000    0.063086\n",
       "0.3  15.556761          0.053333    0.061836\n",
       "0.4   6.892612          0.047500    0.063086\n",
       "0.5  17.475284          0.055333    0.061836\n",
       "0.6  10.974988          0.055000    0.062461\n",
       "0.7   3.853529          0.061905    0.061836\n",
       "0.8   5.462277          0.065833    0.061212\n",
       "0.9   3.053856          0.065556    0.061212"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search best parameter for ridge\n",
    "lgr_ridge = LogisticRegression(penalty='l2', warm_start=False)\n",
    "search_param_by_holdout(lgr_ridge, np.logspace(-3, 2, 100), np.linspace(0.1, 0.9, 9),\n",
    "                        X3_train, y_train, X3_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.599484</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>7.742637</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>7.742637</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>7.742637</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lambda  Validation Error  Test Error\n",
       "0.1  0.003594          0.053333    0.061836\n",
       "0.2  0.599484          0.048333    0.062461\n",
       "0.3  2.154435          0.068889    0.061836\n",
       "0.4  7.742637          0.053333    0.061836\n",
       "0.5  7.742637          0.053333    0.061836\n",
       "0.6  7.742637          0.063889    0.061836\n",
       "0.7  2.154435          0.053333    0.061836\n",
       "0.8  2.154435          0.072917    0.061836\n",
       "0.9  2.154435          0.059259    0.061836"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search best parameter for lasso\n",
    "lgr_lasso = LogisticRegression(penalty='l1', warm_start=False)\n",
    "search_param_by_holdout(lgr_lasso, np.logspace(-3, 2, 10), np.linspace(0.1, 0.9, 9),\n",
    "                        X3_train, y_train, X3_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Fit ridge and LASSO using the k-fold cross-validation approach by searching over k = 2,5,10 and regularization parameters. For value of k, specify the best ‘parameter’, report the average validation error, and the test error generated from training on all the training data using the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to search best parameter by k-fold validation\n",
    "def search_param_by_kfold(lgr, lambdas, Ks, X_train, y_train, X_test, y_test):\n",
    "    result = []\n",
    "    for K in Ks:\n",
    "        print('Processing K = %d' % K)\n",
    "        lambda_, accuracy_valid = cv_kfold(lgr, lambdas, X_train, y_train, K)\n",
    "        lgr.set_params(C=1/lambda_, warm_start=False)\n",
    "        lgr.fit(X_train, y_train)\n",
    "        accuracy_test = lgr.score(X_test, y_test)\n",
    "        result.append([lambda_, 1-accuracy_valid, 1-accuracy_test])\n",
    "        \n",
    "    return pd.DataFrame(result, Ks, ['lambda', 'Validation Error', 'Test Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing K = 2\n",
      "Processing K = 5\n",
      "Processing K = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.636651</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.636651</td>\n",
       "      <td>0.055333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.858668</td>\n",
       "      <td>0.056333</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lambda  Validation Error  Test Error\n",
       "2   2.636651          0.056667    0.061836\n",
       "5   2.636651          0.055333    0.061836\n",
       "10  8.858668          0.056333    0.062461"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search best parameter for ridge\n",
    "search_param_by_kfold(lgr_ridge, np.logspace(-3, 2, 20), [2, 5, 10],\n",
    "                        X3_train, y_train, X3_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.742637</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.599484</td>\n",
       "      <td>0.056333</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lambda  Validation Error  Test Error\n",
       "2   7.742637          0.058333    0.061836\n",
       "5   0.599484          0.056333    0.061212\n",
       "10  2.154435          0.056667    0.061836"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search best parameter for lasso\n",
    "search_param_by_kfold(lgr_lasso, np.logspace(-3, 2, 10), [2, 5, 10],\n",
    "                        X3_train, y_train, X3_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Fit ridge and LASSO using the Monte Carlo Cross-validation approach with 10 samples (i.e., use the validation/hold-out technique from (a) 10 times). For the different user-specified split ratio, specify the best ‘parameter’, report the average validation error, and the test error generated from training on all the training data using the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define convenience method to search best parameter by Monte Carlo validation\n",
    "def search_param_by_monte_carlo(lgr, lambdas, ratios, sampling, X_train, y_train, X_test, y_test):\n",
    "    result = []\n",
    "    for ratio in ratios:\n",
    "        print('Processing ratio = %.1f' % ratio)\n",
    "        lambda_best = None\n",
    "        accuracy_valid_best = 0\n",
    "        for lambda_ in lambdas:\n",
    "            accuracies_valid = []\n",
    "            for i in range(sampling):\n",
    "                _, accuracy_valid = cv_holdout(lgr, [lambda_], X_train, y_train, ratio)\n",
    "                accuracies_valid.append(accuracy_valid)\n",
    "            accuracy_valid_mean = np.array(accuracies_valid).mean()\n",
    "            if accuracy_valid_mean > accuracy_valid_best:\n",
    "                accuracy_valid_best = accuracy_valid_mean\n",
    "                lambda_best = lambda_\n",
    "        \n",
    "        lgr.set_params(C=1/lambda_best, warm_start=False)\n",
    "        lgr.fit(X_train, y_train)\n",
    "        accuracy_test = lgr.score(X_test, y_test)\n",
    "        result.append([lambda_best, 1-accuracy_valid_best, 1-accuracy_test])\n",
    "        \n",
    "    return pd.DataFrame(result, ratios, ['lambda', 'Validation Error', 'Test Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ratio = 0.1\n",
      "Processing ratio = 0.2\n",
      "Processing ratio = 0.3\n",
      "Processing ratio = 0.4\n",
      "Processing ratio = 0.5\n",
      "Processing ratio = 0.6\n",
      "Processing ratio = 0.7\n",
      "Processing ratio = 0.8\n",
      "Processing ratio = 0.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>2.636651</td>\n",
       "      <td>0.054889</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>8.858668</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>2.636651</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>4.832930</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>8.858668</td>\n",
       "      <td>0.061381</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>8.858668</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>4.832930</td>\n",
       "      <td>0.069778</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lambda  Validation Error  Test Error\n",
       "0.1  0.020691          0.051000    0.061836\n",
       "0.2  0.020691          0.055500    0.061836\n",
       "0.3  2.636651          0.054889    0.061836\n",
       "0.4  8.858668          0.056833    0.062461\n",
       "0.5  2.636651          0.056800    0.061836\n",
       "0.6  4.832930          0.057111    0.061212\n",
       "0.7  8.858668          0.061381    0.062461\n",
       "0.8  8.858668          0.063208    0.062461\n",
       "0.9  4.832930          0.069778    0.061212"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search best parameter for ridge\n",
    "search_param_by_monte_carlo(lgr_ridge, np.logspace(-3, 2, 20), np.linspace(0.1, 0.9, 9), 10,\n",
    "                        X3_train, y_train, X3_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ratio = 0.1\n",
      "Processing ratio = 0.2\n",
      "Processing ratio = 0.3\n",
      "Processing ratio = 0.4\n",
      "Processing ratio = 0.5\n",
      "Processing ratio = 0.6\n",
      "Processing ratio = 0.7\n",
      "Processing ratio = 0.8\n",
      "Processing ratio = 0.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.051333</td>\n",
       "      <td>0.061212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>7.742637</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>7.742637</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.166810</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.058810</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.072963</td>\n",
       "      <td>0.061836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lambda  Validation Error  Test Error\n",
       "0.1  0.046416          0.051333    0.061212\n",
       "0.2  7.742637          0.051500    0.061836\n",
       "0.3  7.742637          0.057111    0.061836\n",
       "0.4  0.166810          0.058500    0.061836\n",
       "0.5  2.154435          0.056467    0.061836\n",
       "0.6  2.154435          0.058111    0.061836\n",
       "0.7  2.154435          0.058810    0.061836\n",
       "0.8  2.154435          0.064500    0.061836\n",
       "0.9  2.154435          0.072963    0.061836"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search best parameter for lasso\n",
    "search_param_by_monte_carlo(lgr_lasso, np.logspace(-3, 2, 10), np.linspace(0.1, 0.9, 9), 10,\n",
    "                        X3_train, y_train, X3_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Comment on how the different model selection techniques compare with one another with regards to AUC and classification error, robustness of the validation estimate, and the computational complexities of the three different hold-out techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the computational complexities perspective, Monte Carlo cross-validation is the most expensive, K-fold cross-validation is the second, holdout technique is the cheapest.\n",
    "2. K-Fold and Monte Carlo validations are pretty robust, and both achieve similar accuracy. Holdout is less robust and has high variance, because it doesn't average over several samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
